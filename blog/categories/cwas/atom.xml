<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cwas | Zarrar's Journaling]]></title>
  <link href="http://czarrar.github.io/blog/categories/cwas/atom.xml" rel="self"/>
  <link href="http://czarrar.github.io/"/>
  <updated>2013-11-27T22:46:58-05:00</updated>
  <id>http://czarrar.github.io/</id>
  <author>
    <name><![CDATA[Zarrar Shehzad]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Timing Comparison]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/24/timing-comparison/"/>
    <updated>2013-11-24T15:21:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/24/timing-comparison</id>
    <content type="html"><![CDATA[<h2 id="overview">Overview</h2>

<p>I will be comparing the timing for the following functions:</p>

<ul>
  <li>Degree Centrality</li>
  <li>GLM</li>
  <li>MDMR</li>
  <li>SVM (linear)</li>
  <li>K-Means Clustering</li>
</ul>

<p>This order also reflects the speed result (first is faster).</p>

<h2 id="parameters">Parameters</h2>

<p>I examined the speed for examining connectivity-phenotype relationships for the following parameters:</p>

<ul>
  <li>number of nodes or connectivity maps: <strong>10</strong></li>
  <li>number of elements in each connectivity map: <strong>800</strong></li>
  <li>number of participants: <strong>100</strong></li>
  <li>number of iterations: <strong>100</strong></li>
</ul>

<p>In the case of SVM and K-Means, I did the analysis like I did with MDMR. I examined the fit between one connectivity map per participant and participant group membership. Thus, the analysis was repeated 10 times, one for each connectivity map.</p>

<p>This whole process was repeated 100 times.</p>

<h2 id="system">System</h2>

<p>The timing analysis was performed on a MacBook Pro OSX v10.8 using a 2.53GHz Intel Core 2 Duo with 4GB of RAM.</p>

<h2 id="results">Results</h2>

<p>A graph shows the average timing for each approach across 100 iterations below.</p>

<script type="text/javascript" src="https://www.google.com/jsapi"></script>

<script type="text/javascript">
  google.load("visualization", "1", {packages:["corechart"]});
  google.setOnLoadCallback(drawChart);
  function drawChart() {
    var data = google.visualization.arrayToDataTable([
      ['Method', 'Time'],
      ['Degree',  6],
      ['GLM',  		30],
      ['MDMR',  	52],
      ['SVM',  		229], 
		 ['K-Means', 788]
    ]);

    var options = {
      title: 'Average time (ms) to compute connectivity-phenotype association',
      hAxis: {title: 'Method'}, 
		 legend: {position: 'none'}
    };

    var chart = new google.visualization.ColumnChart(document.getElementById('chart_div'));
    chart.draw(data, options);
  }
</script>

<div id="chart_div" style="width: 500px; height: 300px;"></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Similarity of IQ CWAS Across Scans]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/24/similarity-of-iq-cwas-across-scans/"/>
    <updated>2013-11-24T11:51:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/24/similarity-of-iq-cwas-across-scans</id>
    <content type="html"><![CDATA[<p>Get the overlap (dice) and similarity (spearman) of the IQ CWAS between scans, and estimate the significance. Below are the current results for a simple comparison.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">measures</th>
      <th>values</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">dice</td>
      <td>0.2731</td>
    </tr>
    <tr>
      <td style="text-align: right">pearson</td>
      <td>0.2571</td>
    </tr>
    <tr>
      <td style="text-align: right">spearman</td>
      <td>0.2511</td>
    </tr>
    <tr>
      <td style="text-align: right">kendalls</td>
      <td>0.1695</td>
    </tr>
  </tbody>
</table>

<p>Let’s focus on just the dice and spearman for now. For a proper permutation test, I want to make sure that the permuted subject indices are the same for scan 1 and 2. This would allow one to test the hypothesis of how similar the CWAS results for IQ are between scans when given a random list of participants.</p>

<h2 id="re-running-mdmr-for-scan-2">Re-Running MDMR for Scan 2</h2>

<p>This understanding mean I need to rerun the MDMR for scan 2 using the permutation indices from scan 1. I have created a new script to run these modified MDMR analyses for scan 2.</p>

<p><code>
cd /home2/data/Projects/CWAS/share/nki/05_cwas
./30_mdmr_using_perms.bash
</code></p>

<h2 id="permutations-for-dice-and-spearman">Permutations for dice and spearman</h2>

<p>Now we need to take the extra time to gather p-values for everything so we can threshold and compare. I’ll use some of the false positive code <code>share/results/20_cwas_iq/40_false_positives.R</code> in getting the p-values of the permutations. The result of this inspiration can be found in <code>/home2/data/Projects/CWAS/share/figures/fig_03</code> where I created the <code>E2_compare_scans.R</code> file. This script does the following (among other things):</p>

<ol>
  <li>Read in the permuted Fstats</li>
  <li>Loop through each permutation so you can</li>
  <li>Calculate significance for both scans</li>
  <li>Compare the two scans with dice (p &lt; 0.05) and spearman</li>
  <li>Return this result and loop to #3 for the next permutation</li>
</ol>

<p>Note that I’m not clustering correcting for the dice comparison and I’m using p-values here instead of F-stats.</p>

<h2 id="results">Results</h2>

<p>Highly significant with dice = 0.2731411 (p &lt; 0.001 or p = 0.0003) and spearman rho = 0.2510524 (p &lt; 0.005 or p = 0.004).</p>

<h2 id="update-connectir">Update Connectir</h2>

<p>To do this analysis, I updated the MDMR script to accept an external permutation file. This is with the new option <code>--permfiles</code>. It accepts a list of descriptor files (comma separated) that should reflect the number of factors2perm.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Saturday - Week 47]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/23/saturday-week-47/"/>
    <updated>2013-11-23T13:54:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/23/saturday-week-47</id>
    <content type="html"><![CDATA[<p>This page covers both Saturday and Sunday (which is technically week 48).</p>

<h2 id="todo">TODO</h2>

<ul>
  <li><strong>Permutation test for dice and spearman with IQ CWAS</strong>
    <ul>
      <li><em>DONE</em></li>
    </ul>
  </li>
  <li><strong>Compare computational time for MDMR to other approaches</strong>
    <ul>
      <li><em>DONE</em></li>
    </ul>
  </li>
  <li><strong>Bootstrap analyses</strong>
    <ul>
      <li><em>DONE</em></li>
    </ul>
  </li>
  <li><strong>Compare different distances</strong>
    <ul>
      <li><em>DONE WITH TABLES</em></li>
      <li><em>GENERATE SURFACE RESULTS</em></li>
      <li><em>WRITE TEXT FOR PAPER</em></li>
      <li><em>UPDATE RESPONSE</em></li>
    </ul>
  </li>
  <li><strong>Simulations</strong>
    <ul>
      <li><em>WRITE CODE</em></li>
      <li><em>GENERATE PLOTS</em></li>
      <li><em>ADD TO RESPONSE LETTER</em></li>
    </ul>
  </li>
  <li><strong>Results</strong>
    <ul>
      <li><em>RE-COMPUTE WHERE NEEDED</em></li>
      <li><em>ADD TO PAPER</em></li>
    </ul>
  </li>
  <li><strong>Update paper with stuff from response letter</strong>
    <ul>
      <li><em>I guess waiting for feedback on response letter</em></li>
    </ul>
  </li>
</ul>

<h2 id="similarity-of-iq-cwas-across-scans">Similarity of IQ CWAS across scans</h2>

<p>See details at <a href="/2013/11/24/similarity-of-iq-cwas-across-scans/">my other post</a>.</p>

<p>Highly significant with dice = 0.2731411 (p &lt; 0.001 or p = 0.0003) and spearman rho = 0.2510524 (p &lt; 0.005 or p = 0.004).</p>

<h2 id="computational-time">Computational Time</h2>

<p>Below is the average time (ms) across 100 iterations. MDMR is a little slower than GLM but comparable.</p>

<p><code>
   method      time
1  Degree   5.76817
2     GLM  30.12167
3    MDMR  51.73251
4     SVM 228.89548
5 K-Means 788.41195
</code></p>

<p>Further details can be found on the <a href="/2013/11/24/timing-comparison/">following post</a>.</p>

<h2 id="comparing-distances">Comparing Distances</h2>

<p>Further details can be found on the <a href="/2013/11/09/comparing-distances">following post</a>.</p>

<h2 id="simulations">Simulations</h2>

<p>Getting a late start on the simulations. </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Comparing Distances]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/09/comparing-distances/"/>
    <updated>2013-11-09T18:02:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/09/comparing-distances</id>
    <content type="html"><![CDATA[<p>We want to show that the choice of your distance metric won’t substantially change your results. I’ll be using the first scan of the IQ dataset. I would like to compare the following measures:</p>

<ul>
  <li>Pearson Correlation</li>
  <li>Spearman Rank</li>
  <li>Kendall Tau</li>
  <li>Lin’s concordance correlation</li>
  <li>Euclidean distance</li>
  <li>Chebychev distance</li>
  <li>Mahalanobis distance</li>
</ul>

<p>All the measures except the last are used in the Zapala et al. (2006) <em>PNAS</em> paper, and the last measure is something used in Kriegeskorte’s work. It is essentially the mean distance between two features/vectors relative to the variance in each of them. Thus, 2 sets of points could be very close on average but have huge variability, meaning that small distance is less meaningful.</p>

<h1 id="low-level-code">Low-Level Code</h1>

<p>Most of the measures are fairly straightforward. I will add them all to the internal <code>.subdist_distance</code> function, which is called to compute the distance between the different participant connectivity maps for a given voxel. Right now, I have the pearson distance, shrinkage pearson distance, and inverse covariance distance. I added the other distance functions from my list above as additional options.</p>

<p>How do you call the different distances? Note that I have made all of these functions internal so you would call it internally (within the package) as <code>.subdist_distance</code>. However, below I will use the globally accessible <code>test_sdist</code> function that is a simple wrapper around <code>.subdist_distance</code>.</p>

<p>``` r</p>

<p>.test_sdist(seedMaps, dmats, colind, method=”pearson”)</p>

<p>```</p>

<p>As you can see, we pass a matrix of participant seed maps (voxels as rows and participants as columns), a big matrix of distances (columns as voxels and rows as the vectorized distance matrix for that voxel), the index of the voxel examined in the distances, and your method of choice.</p>

<h2 id="measures">Measures</h2>

<h3 id="pearson">Pearson</h3>

<p>I updated the connectir pearson distance C function (<code>subdist_pearson_distance</code>) to compute the transformed correlation that has euclidean properties. I should make sure to test this for confirmation.</p>

<h3 id="mahalanobis-distance">Mahalanobis Distance</h3>

<p>I borrowed code for this measure from the following two links:</p>

<p>http://stats.stackexchange.com/questions/33518/pairwise-mahalanobis-distance-in-r</p>

<p>http://stats.stackexchange.com/questions/65705/pairwise-mahalanobis-distance/66325#66325</p>

<p><code>r
library(connectir)
library(corpcor)
seedMaps &lt;- t(matrix(runif(500, min=0, max=2), 100, 5))
# invCov &lt;- ginv(cov(seedMaps))
invCov &lt;- invcov.shrink(seedMaps)
SQRT &lt;- with(svd(invCov), u %*% diag(d^0.5) %*% t(v))
dmat &lt;- as.matrix(dist(seedMaps %*% SQRT))
</code></p>

<p>Note that here I am using a shrinkage method to deal with the ill-posed problem of inverting a n « p issue. So far it normally fails if I take the traditional approach.</p>

<h3 id="concordance">Concordance</h3>

<p>I took the implementation in the <code>epiR</code> package and made it more suitable for a matrix approach (e.g., correlated everything with everything else). Note that the results using this alternative matrix-based approach are very close to using the epiR function but not exact. Should investigate in the future.</p>

<h3 id="others">Others</h3>

<p>Here’s some example code from the spearman distance. For the most part, I tried to use the currently available functions.</p>

<p><code>r
.distance_spearman &lt;- function(seedMaps, dmats, colind, transpose=FALSE, ...) {
    seedMaps &lt;- ifelse(transpose, t(seedMaps[,]), seedMaps[,])
    smat &lt;- cor(seedMaps, method="spearman")
    dmat &lt;- sqrt(2*(1-smat))
    dmats[,colind] &lt;- as.vector(dmat)
}
</code></p>

<h2 id="issues">Issues</h2>

<p>I had an NaN error after running the first pearson distance. I realized that this error is related to the fact that the correlation can sometimes go over 1 due to precision errors. To combat this I added a tolerance level, where I adjust the correlation down by 1e-8. This should ensure that no correlation is above 1, which would lead to a negative number in the transformation and a NaN when trying to get the square root. Note that this is really only an issue for the pearson distance.</p>

<h1 id="higher-level-code">Higher-Level Code</h1>

<p>After computing the connectivity maps, I’d ideally want to have some manual code that runs all the possible distances and saves them in different file-backed distance matrices. However, this seems to be a bit hairy and would require lots of coding/testing. Main issues are with memory (i.e., holding all the distances in memory or partially in memory). Instead, I’ll take the easier but longer approach of running the distances for each method separately. To speed things up, I plan to use the 800 random ROIs.</p>

<p>The details for this code can be found in <code>10_subdist.bash</code>.</p>

<h1 id="running-the-analyses">Running the Analyses</h1>

<p>I’ve started to run the analyses. I ended up going with two separate workflows since the kendall was taking forever!</p>

<p>I will need to re-run the concordance since there was an error in the code. I should make sure to remove the following folder beforehand: <code>/home/data/Projects/CWAS/nki/cwas/short/try_distances/concordance_k0800_to_k0800</code>.</p>

<blockquote>
  <p>Below the time in parentheses represents computation time but excludes setup time (i.e., reading in distance matrix and creating the hat matrix).</p>
</blockquote>

<h2 id="finished">Finished</h2>

<ul>
  <li>Pearson (0.9 mins)</li>
  <li>Spearman (2.5 mins)</li>
  <li>Chebyshev (25 mins)</li>
  <li>Euclidean (6.8 mins)</li>
  <li>Kendall (1883.3 mins)</li>
  <li>Concordance (0.4 mins)</li>
  <li>Mahalanobois (14.5 mins)</li>
</ul>

<h1 id="comparing-distances">Comparing Distances</h1>

<p>Here is some quick code to compare the MDMR results using the different distance measures.</p>

<p><code>r
# Setup
setwd("/home2/data/Projects/CWAS/nki/cwas/short/try_distances/")
library(bigmemory)
dirs &lt;- Sys.glob("*/iq_age+sex+meanFD.mdmr/pvals.desc")
pvals.mat &lt;- sapply(dirs, function(d) attach.big.matrix(d)[,1])
colnames(pvals.mat) &lt;- sub("_k0800_to_k0800", "", dirname(dirname(dirs)))
# reorder according to Zapala paper
tmp &lt;- pvals.mat[,c(6,7,4,2,3,1,5)]
# Percent significant
round(cbind(
	'1'=colMeans(tmp&lt;0.01), 	
	'5'=colMeans(tmp&lt;0.05), 
	'25'=colMeans(tmp&lt;0.25), 
	'50'=colMeans(tmp&lt;0.50)
)*100, 1)
# Correlate
cor(pvals.mat, method="s")
# Dice-esque
d.mat &lt;- crossprod(tmp&lt;0.05)
print(d.mat) # counts
round(sweep(d.mat, 1, diag(d.mat), '/')*100, 2) # percent overlap
# Dice
numer &lt;- 2*d.mat
denom &lt;- (diag(d.mat) %*% t(rep(1,7))) + t(diag(d.mat) %*% t(rep(1,7)))
dice &lt;- numer/denom
print(round(dice, 2))
# Voxels present in all distance measures
sum(rowSums(pvals.mat&lt;0.05)==6)
</code></p>

<p>Interesting that the correlation-based measures are all alike: concordance, kendall, pearson, and spearman with pearson as the most sensitive (180 significant voxels). Then euclidian and mahalanobois are fairly similar with both being the most sensitive overall (194 and 195 significant voxels, respectively). Significance here is p &lt; 0.05 (uncorrected…running analyses for corrected version now).</p>

<p>It’s also interesting that there are still differences in what voxel’s are identified as significant between the euclidian-based ones and the correlation-ones. For instance about 103 voxels are commonly significant between mahalanobois and pearson distance. If I look at those that are not common between mahalanobois and pearson distance, I do find that some of them are sub-threshold in the other measure. For instance, with p&lt;0.1 for pearson there are now 141 significant voxels in common with mahalanobois of p&lt;0.05.</p>

<h1 id="plotting">Plotting</h1>

<p>I want to now plot the different distances in surface.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rerunning CWAS using Transformed Correlations]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/05/rerunning-cwas-using-transformed-correlations/"/>
    <updated>2013-11-05T20:26:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/05/rerunning-cwas-using-transformed-correlations</id>
    <content type="html"><![CDATA[<p>We had previously been using the semi-metric <code>1-r</code>, however are now with a reviewer’s suggestion switching to a metric using a slight transformation of the prior person correlation <code>sqrt(2*1-r)</code><sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>. This change although simple will require a massive effort to semi-reanalyze everything.</p>

<p>We also making another change in the way the permuted hat matrices are generated due to a last minute discovery by Phil. Previously, we had permuted the rows for the columns of interest. The issue with this approach is if the variable of interest is correlated with the covariates, then our permutation will effect both the variable of interest and our covariates. Consequently, we will regress out the covariates of non-interest from our variable of interest. We will then have the fitted response and the residuals. We will permute the order of the residuals and then add back the fitted response.</p>

<blockquote>
  <p>Note: I need to ask Phil what the approach is if your variable of interest has more than one column. I’m guessing you apply this procedure to each column of the variable separately?</p>
</blockquote>

<p><figure class="flickr-thumbnail “testing" style="width: 240px;"><a href="http://farm6.staticflickr.com/5510/10896013916_4696b79800_z.jpg" class="fancybox" data-title-id="flickr-photo-10896013916" data-media="photo"><img src="http://farm6.staticflickr.com/5510/10896013916_4696b79800_m.jpg" title="Testing Brain" style="width: 240px; height: 164px;"/></a><figcaption id="flickr-photo-10896013916"><h1><a class="flickr-link" href="http://www.flickr.com/photos/96917171@N07/10896013916">Testing Brain</a> by czarrar</h1><div class="description">my</div></figcaption></figure></p>

<h2 id="code">Code</h2>

<h3 id="transformation-of-distances">Transformation of Distances</h3>

<p>The first order of business is creating a function that easily transforms my big matrices and re-generates the gower centered matrices. A few nuances is that I need to make sure to set the number of threads to use in advance (otherwise all processors will be occupied) and to set the memory limit for gower centering.</p>

<p>The actual command can be called from bash with the following usage:</p>

<p><code>./transform_cor.R distance-descriptor memlimit nthreads</code></p>

<ul>
  <li><em>distance-descriptor</em>: File path to the subject distances descriptor</li>
  <li><em>memlimit</em>: Upper bound on RAM to use</li>
  <li><em>nthreads</em>: Number of threads to use for matrix algebra operations</li>
</ul>

<h3 id="permuting-residuals-of-predictor-variable">Permuting Residuals of Predictor Variable</h3>

<p>I made an addition to the MDMR model generation functions and made the new residual based approach of generating permuted hat matrices, the default. Below is the function (added within two functions). The critical new lines are highlighted.</p>

<p>``` r mark:5-9
permute_rhs_residuals &lt;- function() {
    # H
    Xj      &lt;- rhs
    cols    &lt;- grps %in% u.grps[f.ind]
    ## permute residuals
    for (i in which(cols)) {
        model   &lt;- lm(Xj[,i] ~ Xj[,!cols])
        Xj[,i]  &lt;- model$residuals[o.inds] + model$fitted.values
    }
    ## hat matrixx
    qrX     &lt;- qr(Xj, tol=TOL)
    Q       &lt;- qr.Q(qrX)
    H       &lt;- tcrossprod(Q[,1:qrX$rank])</p>

<pre><code># H2
cols    &lt;- grps %in% u.grps[-f.ind]
Xj      &lt;- rhs[,cols]
qrX     &lt;- qr(Xj, tol = TOL)
Q       &lt;- qr.Q(qrX)
H2      &lt;- H - tcrossprod(Q[, 1:qrX$rank])

H2 } ```
</code></pre>

<h2 id="normandy-aka-redoing-almost-all-figures">Normandy (aka Redoing Almost All Figures)</h2>

<h3 id="what-figures">What Figures</h3>

<p>Below are the list of figures in the main paper and whether I need to redo it or not.</p>

<ol>
  <li><strong>Yes</strong> Since this is an example figure, I don’t think I need to redo the particular analysis. However, I do need to edit the figure so it shows <code>sqrt(2*(1-r))</code>.</li>
  <li><strong>No</strong> Just a table.</li>
  <li><strong>Yes</strong> Redo 2 analyses and 3 surface maps.</li>
  <li><strong>Yes</strong> Redo 2 analyses and 2 histograms <em>(depends on 3)</em>.</li>
  <li><strong>Yes</strong> Redo network summary and surface map <em>(depends on 3)</em>.</li>
  <li><strong>Yes</strong> Redo 3 surface maps <em>(depends on 3)</em>.</li>
  <li><strong>Yes</strong> Redo 6 analyses and 6 surface maps <em>(depends on 3)</em>.</li>
  <li><strong>Yes</strong> Redo 2 scatter plots, 2 analyses, and 4 surface maps.</li>
  <li><strong>Yes</strong> Redo 2 bar plots.</li>
  <li><strong>Yes</strong> Redo 3 analyses, 3 surface maps, and 3 network summaries.</li>
  <li><strong>Yes</strong> Redo 4 analyses and 4 surface maps.</li>
  <li>
    <p><strong>Yes</strong> Redo 3 analyses and 4 surface maps.
Supplementary Figures</p>
  </li>
  <li><strong>Yes</strong> 3 analyses, 3 surface maps, and 2 scatter plots.</li>
  <li><strong>Yes</strong> ?</li>
  <li><strong>Yes</strong> 2 analyses and 2 surface maps.</li>
  <li><strong>Yes</strong> 6 analyses and 6 surface maps.</li>
  <li><strong>Yes</strong> 3 analyses and 3 surface maps.</li>
  <li><strong>Yes</strong> 3+ analyses and 3 plots.</li>
</ol>

<h3 id="figure-3-done">Figure 3 (DONE)</h3>

<h4 id="transformation--mdmr">Transformation + MDMR</h4>

<p>I’m running <code>32_mdmr_runner.bash</code>, which runs the following two commands:</p>

<p><code>bash
./30_mdmr.bash short compcor 8
./30_mdmr.bash medium compcor 8
</code></p>

<p>Each of those in turn will run the following commands (excerpt from longer script):</p>

<p>``` bash
echo “Voxelwise”
sdistdir=”${distbase}/${strategy}_kvoxs${sm}_to_kvoxs${sm}”
curdir=$(pwd)</p>

<p>cd /home2/data/Projects/CWAS/share/lib
./transform_cor.R ${sdistdir}/subdist.desc 30 12
cd $curdir</p>

<p>time connectir_mdmr.R -i ${sdistdir} \
    –formula “FSIQ + Age + Sex + ${scan}_meanFD” \
    –model ${subdir}/subject_info_with_iq_and_gcors.csv \
    –factors2perm “FSIQ” \
    –permutations 14999 \
    –forks 1 –threads 12 \
    –memlimit 12 \
    –save-perms \
    –ignoreprocerror \
    iq_age+sex+meanFD.mdmr
```</p>

<h4 id="multiple-comparisons-correction">Multiple Comparisons Correction</h4>

<p>Then with <code>36_mdmr_correct_runner.bash</code>, I ran the following lines:</p>

<p><code>bash
./34_mdmr_correct.bash short compcor 8; \
./34_mdmr_correct.bash medium compcor 8
</code></p>

<h4 id="plots">Plots</h4>

<p>Ran the same two set of scripts</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/fig_03
./A1_cwas_iq_pysurfer_easythresh.py
./B1_cwas_iq_overlap_easythresh.py
</code></p>

<h3 id="figure-4-done">Figure 4 (DONE)</h3>

<p>This figure examines the percent of significant associations for each permutation (false positives) and creates a histogram.</p>

<h4 id="setup">Setup</h4>

<p>I use a reference set of permutations or my null distribution. I re-ran:</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/nki/05_cwas
# I set the reference mdmr in these scripts
./30_mdmr.bash short compcor 8
./30_mdmr.bash medium compcor 8
</code></p>

<h4 id="analysis">Analysis</h4>

<p>To generate the false positives, see <code>/home2/data/Projects/CWAS/share/results/20_cwas_iq/40_false_positives.R</code>. </p>

<h4 id="plot">Plot</h4>

<p>Then to plot the histogram, see <code>/home2/data/Projects/CWAS/share/figures/fig_03/D_signif_hists.R</code>.</p>

<h3 id="figure-5-done">Figure 5 (DONE)</h3>

<p>The relevant files for plotting are located in this directory <code>/home2/data/Projects/CWAS/share/figures/sfig_yeo</code>.</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/sfig_yeo
./A_pysurfer_yeo_and_cwas_iq.py
./B1_network_byarea.R
./B2_cropify.py
</code></p>

<h3 id="figure-6-done">Figure 6 (DONE)</h3>

<p>The files for plotting are located in <code>/home2/data/Projects/CWAS/share/figures/sfig_neurosynth</code>. Note that you will need to first plot the elements of Figure 3.</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/sfig_neurosynth
./10_combine_pysurfer.py
</code></p>

<h3 id="figure-7-done">Figure 7 (DONE)</h3>

<p>For the mean connectivity regression, I would use the same transformation as redone with Figure 3. I do need to redo the transformation for Figure 7.</p>

<p>The below script will run MDMR for IQ with mean connectivity as a covariate as well as for mean connectivity as the main effect.</p>

<p><code>bash
./30_mdmr_with_gcors.bash short compcor 8; \
./30_mdmr_with_gcors.bash medium compcor 8
</code> </p>

<p>The below script will run MDMR for IQ using GSR corrected data.</p>

<p><code>bash
./33_mdmr_gsr.bash short compcor 8; \
./33_mdmr_gsr.bash medium compcor 8
</code></p>

<h4 id="multiple-comparisons">Multiple Comparisons</h4>

<p><code>bash
# Mean Connectivity
./34_mdmr_correct_with_gcors.bash short compcor 8; \
./34_mdmr_correct_with_gcors.bash medium compcor 8
# GSR
./34_mdmr_correct_gsr.bash short compcor 8; \
./34_mdmr_correct_gsr.bash medium compcor 8
</code></p>

<h4 id="plots-1">Plots</h4>

<p>This is a 3 x 2 plot with </p>

<ul>
  <li>rows = type of processing (GSR, Mean Connectivity, No Correction)</li>
  <li>cols = scan (1, 2)</li>
</ul>

<p>``` bash
cd /home2/data/Projects/CWAS/share/figures/fig_04
# Row 1: GSR
./Aa_cwas_gsr_pysurfer_easythresh.py</p>

<h1 id="row-2-mean-connectivity">Row 2: Mean Connectivity</h1>
<p>./Ab_cwas_mean_connectivity_pysurfer_easythresh.py</p>

<h1 id="row-3-already-run-fig-3">Row 3: Already Run (Fig 3)</h1>
<p>```</p>

<h3 id="figure-8-done">Figure 8 (DONE)</h3>

<p>The relevant scripts to generate the plots are in <code>/home2/data/Projects/CWAS/share/figures/fig_05</code> and <code>/home2/data/Projects/CWAS/share/results/40_mdmr_glm</code> (although I’m not too sure how the second folder is relevant).</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/fig_05
./A_glm_vs_mdmr_scatter_plots.R
./B_surface_glm_vs_mdmr_top_percentiles.py
</code></p>

<h3 id="figure-9-done">Figure 9 (DONE)</h3>

<p>The relevant analytic and plotting scripts are located in <code>/home2/data/Projects/CWAS/share/nki/08_sca_voxelwise</code> and <code>/home2/data/Projects/CWAS/share/nki/08_sca_voxelwise_scan2</code>. There’s actually not much analysis, just compiling the data together.</p>

<p>Note that I will need to also redo the statistics on this graph comparing the different ROI groups within each scan.</p>

<h4 id="scan-1">Scan 1</h4>

<p><code>bash
cd /home2/data/Projects/CWAS/share/nki/08_sca_voxelwise
./10_calc_peaks.bash
./20_select_rois.R
./30_sca.R
./40_plot.R
</code></p>

<h4 id="scan-2">Scan 2</h4>

<p><code>bash
cd /home2/data/Projects/CWAS/share/nki/08_sca_voxelwise_scan2
./10_calc_peaks.bash
./20_select_rois.R
./30_sca.R
./40_plot.R
</code></p>

<h4 id="outputs">Outputs</h4>

<p>The images for both scans should be in <code>figures/fig_06</code>.</p>

<h3 id="figure-10-done">Figure 10 (DONE)</h3>

<p>This figure covers CWAS for three different datasets.</p>

<h4 id="cwas">CWAS</h4>

<h5 id="development">Development</h5>

<p>Scripts are in <code>/home2/data/Projects/CWAS/share/development+motion/04_analysis</code>. I ran it as follows:</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/development+motion/04_analysis
./02a_mdmr.bash # note ran all combos…relevant for supplementary
./04_mdmr_correct.bash
</code></p>

<p><strong>DONE</strong></p>

<h5 id="adhd">ADHD</h5>

<p>Scripts are in <code>/home2/data/Projects/CWAS/share/adhd200_rerun/05_analysis</code>. I ran it as follows:</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/adhd200_rerun/05_analysis
./30_mdmr_combined.bash compcor
./50_mdmr_correct.bash compcor
</code></p>

<p><strong>DONE</strong></p>

<h5 id="ldopa">LDOPA</h5>

<p>Scripts are in <code>/home2/data/Projects/CWAS/share/ldopa/04_analysis</code>. I ran it as follows:</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/ldopa/04_analysis
./02a_mdmr.bash
./04_mdmr_correct.bash compcor
</code></p>

<p><strong>DONE</strong></p>

<h4 id="plots-2">Plots</h4>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/fig_07
./A_pysurfer_easythresh.py
./B1_network_byarea.R
./B2_cropify.py
</code></p>

<p>The output goes to <code>figures/fig_07</code>.</p>

<h3 id="figure-11-done">Figure 11 (DONE)</h3>

<p>This requires redoing all the ROI-based MDMRs for the IQ analysis. Although this particular figure only shows one of the scans, might as well do both scans here as one of the supplementary figures will depend on it.</p>

<p>Below are the commands that I ran. Note that the mdmr commands will also transform the previous distances.</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/nki/05_cwas
./30_mdmr_rois.bash short compcor 0
./34_mdmr_correct_rois.bash short compcor 0
</code></p>

<p>To plot the data in surface space, I need to run the following</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/sfig_roi_comparison
./30_parcellations_pysurfer.py
</code></p>

<p>The results will be in <code>/home2/data/Projects/CWAS/figures/sfig_roi_comparison</code>.</p>

<h3 id="figure-12-done">Figure 12 (DONE)</h3>

<p><strong>I need to redo the MDMR Analyses</strong></p>

<p>Here, we’ll need to redo the 800 parcellations for the other 3 datasets. I should have the IQ results from Figure 11.</p>

<p>``` bash
# Development
cd /home2/data/Projects/CWAS/share/development+motion/04_analysis
./02a_mdmr_rois.bash # this runs correction as well</p>

<h1 id="adhd-1">ADHD</h1>
<p>cd /home2/data/Projects/CWAS/share/adhd200_rerun/05_analysis
./30_mdmr_combined_rois.bash compcor</p>

<h1 id="ldopa-1">LDOPA</h1>
<p>cd /home2/data/Projects/CWAS/share/ldopa/04_analysis
./02a_mdmr_rois.bash
```</p>

<p>To generate the images, do the following:</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/sfig_roi_comparison
./40_comparison_datasets_pysurfer.py
</code></p>

<p>Output can be found in <code>/home2/data/Projects/CWAS/figures/sfig_roi_comparison</code>.</p>

<h3 id="supp-figure-1-done">Supp Figure 1 (DONE)</h3>

<p>This one definitely needs redoing as it directly displays the distances.</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/nki/06_stability
./14_stability_N104.R
./24_zscore_N104.R
</code></p>

<p>Output can be found in <code>/home2/data/Projects/CWAS/nki/stability/N104_compcor_kvoxs_fwhm08_to_kvoxs_fwhm08</code>.</p>

<p>To generate the plots run:</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/fig_02
./A_pysurfer_cv_zscore.py
./B_pysurfer_consistency_zscore.py
./C_scatter_plot_cv_vs_consistency.R
</code></p>

<p>The output will be in <code>figures/fig_02</code>.</p>

<h3 id="supp-figure-2-done">Supp Figure 2 (DONE)</h3>

<p><strong>REDO DUE TO OTHER 3 DATASETS</strong></p>

<p>This figure shows each of the dataset results using the permutation-based correction.</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/sfig_permutation
./A_iq_pysurfer_perms.py
./B_others_pysurfer_perms.py
</code></p>

<p>Output can be found in <code>/home2/data/Projects/CWAS/figures/sfig_permutations</code>.</p>

<h3 id="supp-figure-3-done">Supp Figure 3 (DONE)</h3>

<p>Shows the mean connectivity for IQ dataset.</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/fig_04
./B_cwas_global_pysurfer_easythresh.py
</code></p>

<p>Output can be found in <code>figures/fig_04</code>.</p>

<h3 id="supp-figure-4-done">Supp Figure 4 (DONE)</h3>

<p>This compares preprocessing effects on CWAS for age looking at inclusion/exclusion of global and motion covariates.</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/sfig_dev_global
./A_pysurfer_easythresh.py
./x_comparison.R
</code></p>

<p>Output is in <code>figures/sfig_dev_motion_global</code>.</p>

<h3 id="supp-figure-5-done">Supp Figure 5 (DONE)</h3>

<p>This directly examines the effect of motion across different global correction strategies.</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/sfig_motion
./A_pysurfer_easythresh.py
</code></p>

<p>Output is in <code>figures/sfig_motion</code>.</p>

<h3 id="supp-figure-6-done">Supp Figure 6 (DONE)</h3>

<p>Last one that varies the number of parcellations and examines the effect of parcellation set on 3 different measures.</p>

<p><code>bash
cd /home2/data/Projects/CWAS/share/figures/sfig_roi_comparison
./10_plot_parcel_metrics.R
</code></p>

<p>Output is in <code>figures/sfig_roi_comparison</code>.</p>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>I am still working on getting latex to work so these math equations will be not be displayed well for now.<a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
</feed>
