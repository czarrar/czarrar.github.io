<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cwas | Zarrar's Journaling]]></title>
  <link href="http://czarrar.github.io/blog/categories/cwas/atom.xml" rel="self"/>
  <link href="http://czarrar.github.io/"/>
  <updated>2013-11-05T21:45:35-05:00</updated>
  <id>http://czarrar.github.io/</id>
  <author>
    <name><![CDATA[Zarrar Shehzad]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rerunning CWAS using Transformed Correlations]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/05/rerunning-cwas-using-transformed-correlations/"/>
    <updated>2013-11-05T20:26:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/05/rerunning-cwas-using-transformed-correlations</id>
    <content type="html"><![CDATA[<p>We had previously been using the semi-metric <code>1-r</code>, however are now with a reviewer&rsquo;s suggestion switching to a metric using a slight transformation of the prior person correlation <code>sqrt(2*1-r)</code><sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>. This change although simple will require a massive effort to semi-reanalyze everything.</p>

<h1>Code</h1>

<p>The first order of business is creating a function that easily transforms my big matrices and re-generates the gower centered matrices. A few nuances is that I need to make sure to set the number of threads to use in advance (otherwise all processors will be occupied) and to set the memory limit for gower centering.</p>

<p>The actual command can be called from bash with the following usage:</p>

<p><code>./transform_cor.R distance-descriptor memlimit nthreads</code></p>

<ul>
<li><em>distance-descriptor</em>: File path to the subject distances descriptor</li>
<li><em>memlimit</em>: Upper bound on RAM to use</li>
<li><em>nthreads</em>: Number of threads to use for matrix algebra operations</li>
</ul>


<h1>Normandy (aka Redoing Almost All Figures)</h1>

<h2>What Figures</h2>

<p>Below are the list of figures in the main paper and whether I need to redo it or not.</p>

<ol>
<li><strong>Yes</strong> Since this is an example figure, I don&rsquo;t think I need to redo the particular analysis. However, I do need to edit the figure so it shows <code>sqrt(2*(1-r))</code>.</li>
<li><strong>No</strong> Just a table.</li>
<li><strong>Yes</strong> Redo 2 analyses and 3 surface maps.</li>
<li><strong>Yes</strong> Redo 2 analyses and 2 histograms.</li>
<li><strong>Yes</strong> Redo network summary and surface map.</li>
<li><strong>Yes</strong> Redo 3 surface maps.</li>
<li><strong>Yes</strong> Redo 6 analyses and 6 surface maps.</li>
<li><strong>Yes</strong> Redo 2 scatter plots, 2 analyses, and 4 surface maps.</li>
<li><strong>Yes</strong> Redo 2 bar plots.</li>
<li><strong>Yes</strong> Redo 3 analyses, 3 surface maps, and 3 network summaries.</li>
<li><strong>Yes</strong> Redo 4 analyses and 4 surface maps.</li>
<li><strong>Yes</strong> Redo 3 analyses and 4 surface maps.</li>
</ol>


<p>Supplementary Figures</p>

<ol>
<li><strong>Yes</strong> 3 analyses, 3 surface maps, and 2 scatter plots.</li>
<li><strong>Yes</strong> ?</li>
<li><strong>Yes</strong> 2 analyses and 2 surface maps.</li>
<li><strong>Yes</strong> 6 analyses and 6 surface maps.</li>
<li><strong>Yes</strong> 3 analyses and 3 surface maps.</li>
<li><strong>Yes</strong> 3+ analyses and 3 plots.</li>
</ol>

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>I am still working on getting latex to work so these math equations will be not be displayed well for now.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bootstrap of IQ CWAS]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/04/bootstrap-of-iq-cwas/"/>
    <updated>2013-11-04T23:38:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/04/bootstrap-of-iq-cwas</id>
    <content type="html"><![CDATA[<p>As per one of the reviewer comments, I am assessing the reproducibility of CWAS with a bootstrap analysis. I am only examining the results from the IQ dataset and will be looking at both the scans.</p>

<h2>Analysis</h2>

<p>I conducted the CWAS as a plugin with the <code>boot</code> package. The actual code can be seen with the github gist at the end. Note that the boot package resamples with replacement.</p>

<p>After I got the p-values for each bootstrap, I (based on Phil&rsquo;s suggestion):</p>

<p><blockquote><p>present some sort of map indicating the proportion of times each voxel comes out as significant. This is similar to the &lsquo;bootstrap inclusion frequency&rsquo; proposed in these references below</p></p><p><p>Royston, P. and Sauerbrei, W. (2008). Multivariable Model-building: a pragmatic approach to regression analysis based on fractional polynomials for modeling continuous variables. Wiley.</p></p><p><p>Sauerbrei, W. and Schumacher, M. (1992). A bootstrap resampling procedure for model building: application to the Cox regression model. Statistics in Medicine 11 2093â€“2109.</p><footer><strong>Phil Reiss</strong></footer></blockquote></p>

<p>I was able to do these steps fairly easily.</p>

<h2>Plotting</h2>

<p>The basic plots can be found on <a href="http://rpubs.com/czarrar/cwas-bootstrap.">http://rpubs.com/czarrar/cwas-bootstrap.</a> <strong>TODO</strong>: I am still needing to work through the surface rendering.</p>

<h2>Code</h2>

<p><div><script src='https://gist.github.com/7164165.js?file=cwas_bootstrap.R'></script>
<noscript><pre><code>library(connectir)
library(boot)

# data = model
boot_mdmr &lt;- function(formula, data, indices, sdist, factors2perm) {
    ###
    # Distances
    ###
    
    # We need to sample the distances based on the indices
    # that is we will create a new set of distances with subject indices based on indices
    # This will also create a local copy of the big matrix
    cat(&quot;Subset of subjects in distances\n&quot;)
    sdist &lt;- filter_subdist(sdist, subs=indices)
    
    # Now we can gowerify
    cat(&quot;Gowerify\n&quot;)
    gmat &lt;- gower.subdist2(sdist)
    
    # Info
    nvoxs &lt;- ncol(gmat)
    nsubs &lt;- sqrt(nrow(gmat))
    nperms &lt;- 4999
    nfactors &lt;- 1
    
    
    ###
    # Calculate memory demands
    ###
    opts &lt;- list(verbose=TRUE, memlimit=20, blocksize=0, superblocksize=0)
    opts &lt;- get_mdmr_memlimit(opts, nsubs, nvoxs, nperms, nfactors)
    # this will give opts$blocksize and opts$superblocksize that will
    # limit total RAM usage to 20GB
    
    ###
    # Get the model ready
    ###
    
    cat(&quot;Subset of subjects in model\n&quot;)
    model &lt;- data.frame(data[indices,])
    
    
    ###
    # Call MDMR
    ###
    
    ret &lt;- mdmr(gmat, formula, model, nperms, factors2perm, 
                 superblocksize=opts$superblocksize, blocksize=opts$blocksize)
    
    -log10(ret$pvals[,]) # or should I just return p-values?
}


###
# Bootstrap ROI-based IQ Results
###

# Set parallel processing
nthreads &lt;- 8
set_parallel_procs(1, nthreads, TRUE)

# Read in the distances (using ROI-based distances and not voxelwise here)
#dpath &lt;- &quot;/home2/data/Projects/CWAS/nki/cwas/short/compcor_kvoxs_fwhm08_to_kvoxs_fwhm08/subdist.desc&quot;
dpath &lt;- &quot;/home2/data/Projects/CWAS/nki/cwas/short/compcor_only_rois_random_k0800/subdist.desc&quot;
sdist &lt;- attach.big.matrix(dpath)

# Read in the model
mpath &lt;- &quot;/home2/data/Projects/CWAS/share/nki/subinfo/40_Set1_N104/subject_info_with_iq_and_gcors.csv&quot;
model &lt;- read.csv(mpath)
model &lt;- subset(model, select=c(&quot;FSIQ&quot;, &quot;Age&quot;, &quot;Sex&quot;, &quot;short_meanFD&quot;))

# Set the formula
f     &lt;- ~ FSIQ + Age + Sex + short_meanFD

# Call
results &lt;- boot(data=model, statistic=boot_mdmr, R=500, formula=f, sdist=sdist, factors2perm=&quot;FSIQ&quot;)
</code></pre></noscript></div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CWAS Computational Complexity]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/03/cwas-computational-complexity/"/>
    <updated>2013-11-03T20:06:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/03/cwas-computational-complexity</id>
    <content type="html"><![CDATA[<p>I&rsquo;m trying to address some reviewer questions regarding the computational complexity of CWAS and particularly the MDMR step.</p>

<p>In summary, the complexity (I think) is</p>

<ul>
<li>O(V*n<sup>2</sup>) for computing the distance matrices</li>
<li>O(k*n<sup>2</sup>) for creating the hat matrices</li>
<li>O(n<sup>3</sup>) for gower centering the distance matrices</li>
<li>O(Pxn<sup>2xV</sup>) for MDMR</li>
</ul>


<p>where V = # of voxels, n = # of subjects, k = # of regressors, P = # of permutations.</p>

<p>The real optimization is the final MDMR step, where the traditional MDMR approach is O(Pxn<sup>3xV</sup>) or O(n<sup>3</sup>) whereas ours is O(n<sup>2</sup>).</p>

<h1>About Time Complexity</h1>

<p>My first step here is to build up some knowledge about the computational time needed for computing the different steps. I searched the terms computational complexity and time complexity but could have also looked at Big-O Notation. It seems like time complexity is the most appropriate term.</p>

<p>Efficiency of an algorithm can be measured by [1]:</p>

<ul>
<li>Execution time (time complexity)</li>
<li>Amount of memory required (space complexity)</li>
</ul>


<p>Time complexity expresses the relationship between the size of the size of the input and the run time for the algorithm. There&rsquo;s other relevant information on the wiki page and some online slides [2,3].</p>

<h2>Complexity of Math Operations</h2>

<p>For measuring the complexity of individual operations, wikipedia has a great summary page [4]. Although it gives difference values for the elementary addition and multiplications, it seems one might assume they run in linear or quasi-linear time (based on other pages?). However, technically multiplication is n<sup>2</sup> or n*log(n) (depending on the implementation). Matrix multiplication is n<sup>3</sup>. This is a little weird because I think of the correlation coefficient as n<sup>2</sup> since that is the number of pairwise correlations you are computing and according to a cs stackexchange post, pearson correlation is O(n) [5].</p>

<h1>CWAS Complexity</h1>

<p>So I guess that&rsquo;s all the background I need. Now let&rsquo;s figure out the complexity of CWAS. Since the computation of the connectivity maps is shared amongst many algorithms, I will ignore that step and start from the computation of the distance matrices.</p>

<h2>Distance Matrices</h2>

<p>This step is done independently at each voxel. And, at a voxel, we have connectivity with m voxels across n participants. On this <code>mxn</code> matrix, we compute the pearson correlation between the m connectivity maps for all possible pairs of participants. Assuming that each correlation is computed in O(n) time [5], changing the number of voxels will lead to an O(n) change while changing the number of subjects will lead to an O(n<sup>2</sup>) change. Thus, this step should be O(V*n<sup>2</sup>).</p>

<h2>MDMR</h2>

<h3>Hat Matrix</h3>

<p>This step involves <code>H = X ( X^T X )^-1 X^T</code>. Note that <code>X</code> is n participants x k regressors. So from the formula, we can see that there are</p>

<ul>
<li>3 matrix algebra operations</li>
<li>1 matrix inversion</li>
<li>2 transpositions (but I won&rsquo;t count those)</li>
</ul>


<p>Each of these operations is O(k<em>n<sup>2</sup>) [4] so this step has O(k</em>n<sup>2</sup>) complexity. This I believe would be around the complexity of multiple linear regression for one voxel as well [6].</p>

<h3>Gower Matrix</h3>

<p>This step involves <code>G = (I - 11^T/n) * A * (I - 11^T/n)</code>. Note that <code>I</code> is the identity matrix (n x n), <code>1</code> is a vector of n 1&rsquo;s, and <code>A</code> is half the squared distance matrix. So from the formula, we can see</p>

<ul>
<li>2 subtractions (additions)</li>
<li>2 divisions (multiplications)</li>
<li>2 matrix multiplications</li>
</ul>


<p>Since the matrix operation will dominate the time, the complexity is O(V*n<sup>3</sup>) where V is the number of voxels.</p>

<h3>Pseudo-F Statistic</h3>

<p>This step involves <code>(HG/(k-1))/((I-H)G/(n-m))</code>. The division parts are not really relevant for the complexity and indeed are not needed when computing the permutations (McArdle and Anderson, 2001), so we actually have <code>(HG)/((I-H)G)</code>. Here H is a vector of hat matrix vectors so it&rsquo;s a P x n<sup>2</sup> matrix (P = # of permutations) and G is a vector of gower matrices so it&rsquo;s a n<sup>2</sup> x V matrix (V = # of voxels). This means that there are:</p>

<ul>
<li>1 subtraction (I-H)</li>
<li>2 matrix multiplications</li>
<li>1 division</li>
</ul>


<p>Since the matrix multiplication takes the dominant time, we can ignore the other two division operations. The computational complexity is then O(Pxn<sup>2xV</sup>) so as in the distance matrix step the complexity will scale by n<sup>2</sup>.</p>

<h1>References</h1>

<ol>
<li><a href="http://www.csd.uwo.ca/courses/CS1037a/notes/topic13_AnalysisOfAlgs.pdf">http://www.csd.uwo.ca/courses/CS1037a/notes/topic13_AnalysisOfAlgs.pdf</a></li>
<li><a href="http://en.wikipedia.org/wiki/Time_complexity">http://en.wikipedia.org/wiki/Time_complexity</a></li>
<li><a href="http://www-fourier.ujf-grenoble.fr/~demailly/manuscripts/kvpy-print.pdf">http://www-fourier.ujf-grenoble.fr/~demailly/manuscripts/kvpy-print.pdf</a></li>
<li><a href="http://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations">http://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations</a></li>
<li><a href="http://cs.stackexchange.com/questions/2604/whats-the-complexity-of-spearmans-rank-correlation-coefficient-computation">http://cs.stackexchange.com/questions/2604/whats-the-complexity-of-spearmans-rank-correlation-coefficient-computation</a></li>
<li><a href="http://math.stackexchange.com/questions/84495/computational-complexity-of-least-square-regression-operation">http://math.stackexchange.com/questions/84495/computational-complexity-of-least-square-regression-operation</a></li>
</ol>

]]></content>
  </entry>
  
</feed>
