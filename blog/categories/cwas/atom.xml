<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cwas | Zarrar's Journaling]]></title>
  <link href="http://czarrar.github.io/blog/categories/cwas/atom.xml" rel="self"/>
  <link href="http://czarrar.github.io/"/>
  <updated>2013-12-17T20:27:16-05:00</updated>
  <id>http://czarrar.github.io/</id>
  <author>
    <name><![CDATA[Zarrar Shehzad]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[CWAS Simulations]]></title>
    <link href="http://czarrar.github.io/blog/2013/12/07/cwas-simulations/"/>
    <updated>2013-12-07T16:39:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/12/07/cwas-simulations</id>
    <content type="html"><![CDATA[<p>It seems that my previous set of simulations may go down the drain as they weren’t relevant to the reviewer’s concern.</p>

<p>So now, I am looking into a new set of simulations focused on examining properties of the MDMR approach using resting-state functional connectivity data.</p>

<h2 id="methods">Methods</h2>

<p>One question is how can we implement our simulations. Here are the general steps:</p>

<ol>
  <li>
    <p>Compute 1000 voxelwise connectivity maps at 4mm isotropic for all my 104 participants.</p>
  </li>
  <li>
    <p>Using GLM remove the effects of other variables to get residual connectivity maps</p>
  </li>
  <li>
    <p>Add in group effect and vary certain factors</p>
  </li>
</ol>

<p>Step three is crucial and is discussed later.</p>

<h3 id="factors">Factors</h3>

<p>What are the factors that we want to measure?</p>

<ul>
  <li>Number of ‘clusters’ that differ</li>
  <li>Extent of each ‘cluster’ that differ</li>
  <li>Effect size</li>
</ul>

<p>Another set of factors that could be examined is the variation in the effect size across the connectivity map. For now, I guess we shall assume a constant difference with some random noise.</p>

<p>Do we really need to be examining some of these steps? I’m thinking that we just focus on the effect size and simply generate a gaussian random field </p>

<h3 id="implementation">Implementation</h3>

<p>I’m assuming that I have a matrix with each participant’s connectivity map at one voxel. </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CWAS Simulations]]></title>
    <link href="http://czarrar.github.io/blog/2013/12/01/cwas-simulations/"/>
    <updated>2013-12-01T21:01:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/12/01/cwas-simulations</id>
    <content type="html"><![CDATA[<p>I should check the data that I am plotted. Right now, I am examining the mean -log10p value of the MDMR results but I think I might want to look at the percent of significant results with each effect size. Should double check.</p>

<p>The code for the simulation analysis is located in <code>/home/data/Projects/CWAS/share/simulations</code>. I have added multiprocessing functionality to speed up the ability to go through the different parameters and iterations.</p>

<p>I have started running one iteration of things including both variables of interest. Holy crap, it finished in like 30mins, super quick. I saved the values in an rda file within the same folder. The contents of that rda are as follows:</p>

<ul>
  <li>logp.cov1</li>
  <li>fstat.cov1</li>
  <li>logp.cov0</li>
  <li>fstat.cov0</li>
</ul>

<p>The <code>cov1</code> term means that the covariate was modeled whereas <code>cov0</code> means the covariate wasn’t modeled. For <code>cov1</code> matrices, the dimensions were 2 terms x 11 group difference x 11 correlation. For <code>cov0</code> matrices, the dimensions were 11 group difference x 11 correlation (only for the group difference term). The correlation was between the age covariate and the response.</p>

<h2 id="plot">Plot</h2>

<p>I generated plots of the results on my computer using the <code>.../pro42/scripts2add/simulations/20_plot.R</code> script. Since I used Rnotebook, I was able to publish those results online at http://rpubs.com/czarrar/cwas_simulations.</p>

<h2 id="status">Status</h2>

<p>So I had to rerun the analyses since I should have been calculating power as percent of significant iterations (p &lt; 05). I upped the number of iterations to 20, hopefully this is enough.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Week 49 - Sunday]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/30/week-49-sunday/"/>
    <updated>2013-11-30T21:47:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/30/week-49-sunday</id>
    <content type="html"><![CDATA[<p>This is a bit of a cheat since I started this on Saturday (week 48).</p>

<h2 id="todo">TODO</h2>

<p>I’m trying to use the workflow for this.</p>

<h2 id="comparing-distances">Comparing Distances</h2>

<p>I was able to finish making the figure as well as the text for the paper. I added all this information to the response letter.</p>

<h2 id="simulations">Simulations</h2>

<p>I ran this and need to double check. However, I do think that something went wrong here. I need to double check the code and spot check the effect sizes given. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Timing Comparison]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/24/timing-comparison/"/>
    <updated>2013-11-24T15:21:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/24/timing-comparison</id>
    <content type="html"><![CDATA[<h2 id="overview">Overview</h2>

<p>I will be comparing the timing for the following functions:</p>

<ul>
  <li>Degree Centrality</li>
  <li>GLM</li>
  <li>MDMR</li>
  <li>SVM (linear)</li>
  <li>K-Means Clustering</li>
</ul>

<p>This order also reflects the speed result (first is faster).</p>

<h2 id="parameters">Parameters</h2>

<p>I examined the speed for examining connectivity-phenotype relationships for the following parameters:</p>

<ul>
  <li>number of nodes or connectivity maps: <strong>10</strong></li>
  <li>number of elements in each connectivity map: <strong>800</strong></li>
  <li>number of participants: <strong>100</strong></li>
  <li>number of iterations: <strong>100</strong></li>
</ul>

<p>In the case of SVM and K-Means, I did the analysis like I did with MDMR. I examined the fit between one connectivity map per participant and participant group membership. Thus, the analysis was repeated 10 times, one for each connectivity map.</p>

<p>This whole process was repeated 100 times.</p>

<h2 id="system">System</h2>

<p>The timing analysis was performed on a MacBook Pro OSX v10.8 using a 2.53GHz Intel Core 2 Duo with 4GB of RAM.</p>

<h2 id="results">Results</h2>

<p>A graph shows the average timing for each approach across 100 iterations below.</p>

<script type="text/javascript" src="https://www.google.com/jsapi"></script>

<script type="text/javascript">
  google.load("visualization", "1", {packages:["corechart"]});
  google.setOnLoadCallback(drawChart);
  function drawChart() {
    var data = google.visualization.arrayToDataTable([
      ['Method', 'Time'],
      ['Degree',  6],
      ['GLM',  		30],
      ['MDMR',  	52],
      ['SVM',  		229], 
		 ['K-Means', 788]
    ]);

    var options = {
      title: 'Average time (ms) to compute connectivity-phenotype association',
      hAxis: {title: 'Method'}, 
		 legend: {position: 'none'}
    };

    var chart = new google.visualization.ColumnChart(document.getElementById('chart_div'));
    chart.draw(data, options);
  }
</script>

<div id="chart_div" style="width: 500px; height: 300px;"></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Similarity of IQ CWAS Across Scans]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/24/similarity-of-iq-cwas-across-scans/"/>
    <updated>2013-11-24T11:51:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/24/similarity-of-iq-cwas-across-scans</id>
    <content type="html"><![CDATA[<p>Get the overlap (dice) and similarity (spearman) of the IQ CWAS between scans, and estimate the significance. Below are the current results for a simple comparison.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">measures</th>
      <th>values</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">dice</td>
      <td>0.2731</td>
    </tr>
    <tr>
      <td style="text-align: right">pearson</td>
      <td>0.2571</td>
    </tr>
    <tr>
      <td style="text-align: right">spearman</td>
      <td>0.2511</td>
    </tr>
    <tr>
      <td style="text-align: right">kendalls</td>
      <td>0.1695</td>
    </tr>
  </tbody>
</table>

<p>Let’s focus on just the dice and spearman for now. For a proper permutation test, I want to make sure that the permuted subject indices are the same for scan 1 and 2. This would allow one to test the hypothesis of how similar the CWAS results for IQ are between scans when given a random list of participants.</p>

<h2 id="re-running-mdmr-for-scan-2">Re-Running MDMR for Scan 2</h2>

<p>This understanding mean I need to rerun the MDMR for scan 2 using the permutation indices from scan 1. I have created a new script to run these modified MDMR analyses for scan 2.</p>

<p><code>
cd /home2/data/Projects/CWAS/share/nki/05_cwas
./30_mdmr_using_perms.bash
</code></p>

<h2 id="permutations-for-dice-and-spearman">Permutations for dice and spearman</h2>

<p>Now we need to take the extra time to gather p-values for everything so we can threshold and compare. I’ll use some of the false positive code <code>share/results/20_cwas_iq/40_false_positives.R</code> in getting the p-values of the permutations. The result of this inspiration can be found in <code>/home2/data/Projects/CWAS/share/figures/fig_03</code> where I created the <code>E2_compare_scans.R</code> file. This script does the following (among other things):</p>

<ol>
  <li>Read in the permuted Fstats</li>
  <li>Loop through each permutation so you can</li>
  <li>Calculate significance for both scans</li>
  <li>Compare the two scans with dice (p &lt; 0.05) and spearman</li>
  <li>Return this result and loop to #3 for the next permutation</li>
</ol>

<p>Note that I’m not clustering correcting for the dice comparison and I’m using p-values here instead of F-stats.</p>

<h2 id="results">Results</h2>

<p>Highly significant with dice = 0.2731411 (p &lt; 0.001 or p = 0.0003) and spearman rho = 0.2510524 (p &lt; 0.005 or p = 0.004).</p>

<h2 id="update-connectir">Update Connectir</h2>

<p>To do this analysis, I updated the MDMR script to accept an external permutation file. This is with the new option <code>--permfiles</code>. It accepts a list of descriptor files (comma separated) that should reflect the number of factors2perm.</p>
]]></content>
  </entry>
  
</feed>
