<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cpac | Zarrar's Journaling]]></title>
  <link href="http://czarrar.github.io/blog/categories/cpac/atom.xml" rel="self"/>
  <link href="http://czarrar.github.io/"/>
  <updated>2013-12-30T17:23:48-05:00</updated>
  <id>http://czarrar.github.io/</id>
  <author>
    <name><![CDATA[Zarrar Shehzad]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Fast Eigenvector Centrality]]></title>
    <link href="http://czarrar.github.io/blog/2013/12/27/fast-eigenvector-centrality/"/>
    <updated>2013-12-27T19:15:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/12/27/fast-eigenvector-centrality</id>
    <content type="html"><![CDATA[<p>I’m working on adding the fast eigenvector centrality code<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> to CPAC. A big thing about the fast code is that it only works with unthresholded data. So one thing that we will do is </p>

<h2 id="unit-testing">Unit Testing</h2>

<p>I have a set of unit tests in <code>CPAC/network_centrality/tests/core.py</code>. I don’t like the filename core and should look to changing that. I wonder if the filenames can be somewhat generic with one file that has all the CPAC/nipype relevant code, another that has more utility functions, and a last one that does the core functionality. Something to consider.</p>

<p>So I have tests that use random data and run the following commands to generate the data:</p>

<p><code>python
# Normalize Random Time-Series Data
m = np.random.random((ntpts,nvoxs))
m = norm_cols(m)
# Correlation Data with Range 0-1
mm = m.T.dot(m) # note that need to generate connectivity matrix here
mm = (1+mm)/2  
</code></p>

<p>Note the range of the correlation values is changed to be 0-1 since</p>

<ol>
  <li>Negative values don’t make much sense for the eigenvectors</li>
  <li>The power method used in the fast approach is based on this range</li>
</ol>

<p>Then, we can create the two different outputs based on the original and faster approach.</p>

<p><code>python
ref  = eigenvector_centrality(mm, verbose=False)
comp = fast_eigenvector_centrality(m, verbose=False)  
</code></p>

<p>We finally compare the outputs and make sure they are almost equal, which it should. This degree of similarity however seems to be a little lower when using real data.</p>

<p><code>python
diff = np.abs(ref-comp).mean()
ok_(diff &lt; np.spacing(1e2))  
</code></p>

<h2 id="confusion">Confusion</h2>

<p>One point of confusion is why do you multiply the eigenvectors by your correlation matrix and then divide by your dominant eigenvalue? This is done in CPAC’s standard eigenvector centrality code and likely stems from work in Lohmann et al<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>. TODO: finish this section explaining my possible misunderstanding…</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>todo add citation.<a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>todo add citation.<a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Test Smoothing]]></title>
    <link href="http://czarrar.github.io/blog/2013/12/27/test-smoothing/"/>
    <updated>2013-12-27T17:31:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/12/27/test-smoothing</id>
    <content type="html"><![CDATA[<p>[<strong>Note</strong>: This article was updated on 2013-12-30]</p>

<p>I added a few lines to the cpac pipeline that apply smoothing to the 4D functional file in standard space. The information can be found in <code>/home2/data/Projects/CPAC_Regression_Test/smooth_tests</code>.</p>

<h2 id="cpac-processing">CPAC Processing</h2>

<p>Today, I wanted to start some testing of this new code. I had some issues that were related to not using a most recent version of nipype and also not linking to this version properly. I ran this test on Friday but saw today that the CPAC output appeared a little strange. There were multiple pipeline directories when there should have been only one. I am rerunning it now as I changed the config file from running both ANTS and FSL for registration to just ANTS.</p>

<h2 id="testing">Testing</h2>

<p>The simplest way to test the code is to manually smooth the unsmoothed 4D data and compare it to the smoothed version run with CPAC. I have written such a test in <code>x_compare.py</code> within the same main directory.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Derivative Class]]></title>
    <link href="http://czarrar.github.io/blog/2013/12/20/derivative-class/"/>
    <updated>2013-12-20T21:36:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/12/20/derivative-class</id>
    <content type="html"><![CDATA[<p><strong>Mission:</strong><br />
» Refractor current derivative workflows in <code>cpac_pipeline.py</code> (if you choose to accept it)</p>

<p><strong>Why:</strong><br />
» Easier to read code<br />
» Easier to implement quick packs
» Testing should be much more straightforward
» Potential for an extension-like system for users to integrate their own derivatives in the future (plug-in-play)</p>

<p>I personally have two objectives with these changes based on working with the ABIDE dataset. First, it is to make it easier to use other preprocessed data as inputs to CPAC. Second, it is to add a new derivative (functional density mapping; Tomasi et al., 2010) to the current pipeline system.</p>

<h2 id="how-does-it-currently-work-using-reho-as-an-example">How does it currently work? Using REHO as an example.</h2>

<p>I will be focusing on the <code>CPAC/pipeline/cpac_pipeline.py</code> file. This is a bit of a gargantuan file and contains both high-level (in terms of the pipeline) and low-level code, so it can get a bit confusing to go through. With that said, having everything in one place like this also makes it easier to go through after you know your way around.</p>

<p>I’ll skip past most of this code till about line 1796<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> where the REHO workflow starts. Then, I’ll go line by line (somewhat) to understand what’s happening until line 1833 when this part of the REHO code ends. Let’s begin shall we? I might suggest a good whiskey, it goes well while reading certain code.</p>

<h3 id="getting-our-toes-wet">Getting our toes wet</h3>

<p><code>python
new_stops_list = []
new_strat_list = []
num_strat = 0
</code></p>

<p>The <code>num_strat</code> stores the current strategy number (or index in a list, in this case). A strategy is one while run of the pipeline (i think), and anytime there is a fork in the pipeline (e.g., using versus not using bandpass filtering), a new strategy is created. This is all determined before as the data is preprocessed.</p>

<p>And it seems like the <code>new_stops_list</code> and <code>new_strat_list</code> do not get used in this section. So kindly ignore them. The <code>new_strat_list</code> is usually for when you add a new strategy to the list (i.e., there is a fork in the pipeline).</p>

<h3 id="getting-our-feet-wet">Getting our feet wet</h3>

<p>Ok so we haven’t even scratched the surface yet. Now I’ll throw all the code at you here for this section and then go through it gradually.</p>

<p>``` python
if 1 in c.runReHo:
    for i,strat in enumerate(strat_list):</p>

<pre><code>    preproc = create_reho()
    preproc.inputs.inputspec.cluster_size = c.clusterSize
    reho = preproc.clone('reho_%d' % num_strat)

    try:
        node, out_file = strat.get_leaf_properties()
        workflow.connect(node, out_file,
                         reho, 'inputspec.rest_res_filt')

        node, out_file = strat.get_node_from_resource_pool('functional_brain_mask')
        workflow.connect(node, out_file,
                         reho, 'inputspec.rest_mask')
    except:
        print 'Invalid Connection: REHO:', num_strat, ' resource_pool: ', strat.get_resource_pool()
        raise
</code></pre>

<p>strat.update_resource_pool({‘raw_reho_map’:(reho, ‘outputspec.raw_reho_map’)})
        strat.update_resource_pool({‘reho_Z_img’:(reho, ‘outputspec.z_score’)})
        strat.append_name(reho.name)</p>

<pre><code>    create_log_node(reho, 'outputspec.raw_reho_map', num_strat)
    
    num_strat += 1
</code></pre>

<p>```</p>

<h4 id="lines-1-2">Lines 1-2</h4>

<p><code>python
if 1 in c.runReHo:
    for i,strat in enumerate(strat_list):
</code></p>

<p>For all derivatives, we usually start with an if statement that checks if the user wants to run this particular derivative. Then we loop through each strategy to access the preprocessed functional data. The node information for these files are kept in the <code>strat_list</code>, which is a list of strategy objects. </p>

<h4 id="lines-4-6">Lines 4-6</h4>

<p><code>python
        preproc = create_reho()
        preproc.inputs.inputspec.cluster_size = c.clusterSize
        reho = preproc.clone('reho_%d' % num_strat)
</code></p>

<p>This is a little confusing but <code>preproc</code> is actually a workflow object for running REHO. It needs one input cluster size for the number of neighboring voxels to examine when measuring the regional homogeneity of the time-series. We then clone this reho workflow so that we can have a unique one for each reho named <code>'reho_%d' % num_strat</code>.</p>

<p>Maybe you like me are wondering why you can’t pass the cluster size and the name of the workflow as an argument to <code>create_reho</code>, which would eliminate those two additional lines. Not sure.</p>

<h4 id="lines-9-15">Lines 9-15</h4>

<p>``` python</p>

<p>node, out_file = strat.get_leaf_properties()
workflow.connect(node, out_file, reho, ‘inputspec.rest_res_filt’)</p>

<p>node, out_file = strat.get_node_from_resource_pool(‘functional_brain_mask’)
workflow.connect(node, out_file, reho, ‘inputspec.rest_mask’)</p>

<p>``` </p>

<p>One key step to any derivative is it’s inputs. As I mentioned before the <code>start</code> object holds the node information for the preprocessed functional data. First, we get the filtered functional data <code>inputspec.rest_res_filt</code>. Then, we get the functional brain mask. We will extract REHO estimates from our functional data within our brain mask.</p>

<p>Now you might be wondering, what is the difference between <code>strat.get_leaf_properties()</code> vs. <code>strat.get_node_from_resource_pool('functional_brain_mask')</code>? The former (for the time series) is when one node and output name get added to the <code>start</code> object as a leaf. It appears that there is only one leaf of it’s kind and this is used specifically for functional preprocessed data. This file can be the functional data at different stages of preprocessing depending on either the stage in the pipeline or the preferences of the user. This could be the file preprocessed data, preprocessed + nuisance regression, or preprocess + nuisance regression + filtering. The latter (for the brain mask) is a bit more straightforward and simply gets the information for ‘functional_brain_mask’ in the strat object (an element in a dictionary).</p>

<h4 id="lines-20-24">Lines 20-24</h4>

<p>``` python
        strat.update_resource_pool({‘raw_reho_map’:(reho, ‘outputspec.raw_reho_map’)})
        strat.update_resource_pool({‘reho_Z_img’:(reho, ‘outputspec.z_score’)})
        strat.append_name(reho.name)</p>

<pre><code>    create_log_node(reho, 'outputspec.raw_reho_map', num_strat)
</code></pre>

<p>```</p>

<p>These functions all have to do with adding the files generated by our reho workflow into the <code>start</code> object. Specifically, we will be adding the raw reho map and the Z-score transformed reho map. The last line here is related to keeping a log of this REHO workflow by creating a new log node.</p>

<p>Also I have no idea what the <code>strat.append_name</code> is about. Will need to find out.</p>

<h4 id="lines-26-27">Lines 26-27</h4>

<p><code>python
        num_strat += 1
stops_list += new_stops_list
strat_list += new_strat_list
</code></p>

<p>I’ve sort-of gone through these lines before so I’ll spare you the repetition.</p>

<h2 id="improving-this-code">Improving this code?</h2>

<p>I picked a pretty easy derivative. I mentioned some avenues of improvement. The function that generates the derivative workflow should be able to take in arguments. The <code>get_leaf_properties</code> is a little confusing and should be replaced.</p>

<p>The other avenue of improvement is the possibility that much of this is repeated in the other derivatives. You have some input functional data from the <code>strat</code> object and you need to save some output data into the <code>strat</code> object. We should be able to create an abstract <code>Derivative</code> class.</p>

<p>So we take in some inputs that are in the strat class and we give them to the reho class.</p>

<p>Below is a very rough and quick switch of this process.</p>

<p>``` python
class Derivative(object):
    “"”For adding a derivative to your workflow”””
    def <strong>init</strong>(self, fun, workflow, strat, <em>args, **kwrds):
        super(Derivative, self).<strong>init</strong>()
        self.workflow = workflow
        self.strat = strat
        self.args = args
        self.kwrds = kwrds
        self.deriv = func(</em>args, **kwrds)</p>

<pre><code>def connect_inputs(**kwrds):
    for deriv_in,strat_out in kwrds.iteritems():
        node,out_file = self.strat.get_node_from_resource_pool(strat_out)
        self.workflow.connect(node, out_file, 
                              self.deriv, 'inputspec.%s' % deriv_in)

def connect_outputs(**kwrds):
    for strat_in,deriv_out in kwrds.iteritems():
        strat.update_resource_pool({strat_in: (self.deriv, deriv_out)})
</code></pre>

<p>```</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>The exact line number (1796) will vary depending on your version. Just search ‘Inserting REHO’ and you’ll be golden.<a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DPARSF Quick Pack]]></title>
    <link href="http://czarrar.github.io/blog/2013/12/18/dparsf-quick-pack/"/>
    <updated>2013-12-18T17:14:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/12/18/dparsf-quick-pack</id>
    <content type="html"><![CDATA[<p>I want to first get down what files from the DPARSF preprocessed output correspond to inputs needed by CPAC for running the derivatives.</p>

<p>A big thing here is that I am running DPARSF in native space. Then on the this derivative data, I would normalize it using DARTELS. And I guess then apply smoothing using DPARSF. How to I apply smoothing with Chao-Gan’s script (emailed him to find out)?</p>

<h2 id="naming-conventions">Naming Conventions</h2>

<p><code>
A=slice timing
R=renormalization
C=covariate regressed
W=spatially normalized
S=smoothed
F=filtered
Sym=for VMH
global=GSR
</code></p>

<h2 id="anatomical">Anatomical</h2>

<p>I don’t need any of these since they are only for registration</p>

<h2 id="functional">Functional</h2>

<ul>
  <li>functional_brain_mask</li>
  <li>functional_nuisance_residuals</li>
  <li>functional_freq_filtered</li>
  <li></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CPAC Derivative Inputs]]></title>
    <link href="http://czarrar.github.io/blog/2013/12/17/cpac-derivative-inputs/"/>
    <updated>2013-12-17T19:24:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/12/17/cpac-derivative-inputs</id>
    <content type="html"><![CDATA[<p>I want to try to organize what inputs are needed for what derivates for CPAC. First, I have the list of template inputs for quick pack for the CCS pipeline:</p>

<p>``` python
anat_suffixes = {
    “anatomical_brain”: “mprage_sanlm.nii.gz”,     # check
    “anatomical_reorient”: “reg/highres_rpi.nii.gz”, 
    “anatomical_to_mni_nonlinear_xfm”: “reg/highres2standard_warp.nii.gz”, 
    “mni_normalized_anatomical”: “reg/fnirt_highres2standard.nii.gz”, 
}</p>

<p>func_suffixes = {
    “preprocessed”: “rest_res.nii.gz”, 
    “mean_functional”: “rest_pp_mean.nii.gz”, 
    “functional_brain_mask”: “rest_pp_mask.nii.gz”, 
    “functional_nuisance_residuals”: “rest_pp_nofilt_sm0.nii.gz”,<br />
    “functional_freq_filtered”: [”%(strategy)srest_pp<em>%(pipeline)s_sm0.nii.gz”, “%(strategy)s/rest_pp</em>%(pipeline)s_sm0.nii.gz”],
    “functional_mni”: [”%(strategy)srest.%(pipeline)s.sm0.mni152.nii.gz”, “%(strategy)s/rest.%(pipeline)s.sm0.mni152.nii.gz”],
    “functional_brain_mask_to_standard”: “” # I would need to make this myself
}</p>

<p>reg_suffixes = {
    “functional_to_anat_linear_xfm”: “reg/example_func2highres.mat” 
#    “functional_to_mni_linear_xfm”: “functional_to_mni_linear_xfm.mat”
} </p>

<p>```</p>

<p>Now I go through each of the files to see if they are really needed. If not, then I will want to make sure that it is also processed as optional in my ghetto quick pack code.</p>

<h2 id="anatomicals">Anatomicals</h2>

<h3 id="anatomicalbrain">anatomical_brain</h3>

<p><strong>Yes</strong> it is needed for <strong>all the steps</strong> but <strong>only with ANTS</strong>. It is used by the applywarp sections of code and I think particularly for transforming FSL’s registration matrix to ANTs format (again i think).</p>

<h3 id="anatomicalreorient">anatomical_reorient</h3>

<p>Only <strong>VMHC?</strong>.</p>

<h3 id="anatomicaltomninonlinearxfm">anatomical_to_mni_nonlinear_xfm</h3>

<p><strong>Yes</strong> for <strong>all the steps</strong> but <strong>only for applying the registration</strong>.</p>

<h3 id="mninormalizedanatomical">mni_normalized_anatomical</h3>

<p><strong>No</strong>. This is only used in QC and so this can be removed from the set of inputs that I generate.</p>

<h2 id="functional">Functional</h2>

<h3 id="preprocessed">preprocessed</h3>

<p><strong>No</strong>. This is used in scrubbing and QC so it too can be removed from the set of inputs that I generate.</p>

<h3 id="meanfunctional">mean_functional</h3>

<p><strong>No but in VMHC</strong> it is used. Not sure how long that will last.</p>

<h3 id="functionalbrainmask">functional_brain_mask</h3>

<p><strong>Yes</strong> it is used in <strong>many (all?) steps</strong>.</p>

<h3 id="functionalnuisanceresiduals">functional_nuisance_residuals</h3>

<p><strong>Yes</strong> for <strong>ALFF and fALFF</strong>. Note that this uses the set_leaf_properties and get_leaf_properties function to dynamically get so it won’t be so obvious. This option can also be used for the other derivatives if you don’t want them to be filtered.</p>

<h3 id="functionalfreqfiltered">functional_freq_filtered</h3>

<p><strong>Yes</strong> for <strong>everything where want filtering</strong>.</p>

<h3 id="functionalmni">functional_mni</h3>

<p><strong>Yes</strong> for <strong>Spatial Regression, ROI time series, Voxel time series, Temporal Regression for SCA, Network Centrality</strong></p>

<h3 id="functionalbrainmasktostandard">functional_brain_mask_to_standard</h3>

<p><strong>Yes</strong> but <strong>only when apply registration</strong>. Although should also need it for the above ones…</p>

<h2 id="final">Final</h2>

<p>Ok so the final list, here again. Note that I didn’t discuss the reg one.</p>

<p>``` python
anat_suffixes = {
    “anatomical_brain”: “mprage_sanlm.nii.gz”,          # REGISTRATION
    “anatomical_reorient”: “reg/highres_rpi.nii.gz”,    # VMHC?
    “anatomical_to_mni_nonlinear_xfm”: “reg/highres2standard_warp.nii.gz”,  # REGISTRATION
#    “mni_normalized_anatomical”: “reg/fnirt_highres2standard.nii.gz”,      # NOT NEEDED 
}</p>

<p>func_suffixes = {
#    “preprocessed”: “rest_res.nii.gz”,             # NOT NEEDED
#    “mean_functional”: “rest_pp_mean.nii.gz”,      # VMHC?
    “functional_brain_mask”: “rest_pp_mask.nii.gz”, # YES 
    “functional_nuisance_residuals”: “rest_pp_nofilt_sm0.nii.gz”,  # YES (although not really used)
    “functional_freq_filtered”: [”%(strategy)srest_pp<em>%(pipeline)s_sm0.nii.gz”, “%(strategy)s/rest_pp</em>%(pipeline)s_sm0.nii.gz”],    # YES
    “functional_mni”: [”%(strategy)srest.%(pipeline)s.sm0.mni152.nii.gz”, “%(strategy)s/rest.%(pipeline)s.sm0.mni152.nii.gz”],      # YES
    “functional_brain_mask_to_standard”: “”                                                                                         # Yes
}</p>

<p>reg_suffixes = {
    “functional_to_anat_linear_xfm”: “reg/example_func2highres.mat” # REGISTRATION 
#    “functional_to_mni_linear_xfm”: “functional_to_mni_linear_xfm.mat”
} </p>

<p>```</p>
]]></content>
  </entry>
  
</feed>
