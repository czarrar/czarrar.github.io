<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: work | Zarrar's Journaling]]></title>
  <link href="http://czarrar.github.io/blog/categories/work/atom.xml" rel="self"/>
  <link href="http://czarrar.github.io/"/>
  <updated>2013-12-21T18:38:40-05:00</updated>
  <id>http://czarrar.github.io/</id>
  <author>
    <name><![CDATA[Zarrar Shehzad]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Week 50 - Friday]]></title>
    <link href="http://czarrar.github.io/blog/2013/12/13/week-50-friday/"/>
    <updated>2013-12-13T12:01:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/12/13/week-50-friday</id>
    <content type="html"><![CDATA[<p>There’s been a bit of a lull in writing these entries. Hoping to get back on the train.</p>

<p><strong>What are the dominant issues for today?</strong></p>

<ul>
  <li>
    <p>I found that yesterday that the fast eigencentrality code doesn’t work when the inputs are normalized data (mean=0, sd=1). I am not totally sure what’s going on but I can try to use the matlab code directly to see if my python port is missing something. I might first try with random data and then with some imaging data if possible. The imaging data could be used to directly compare with the python code. I might keep these test code blocks as gists.</p>
  </li>
  <li>
    <p>I should make a table of all the processing steps that are needed for the ABIDE dataset. I want to run some of these things in the background as I can so as not to pile up.</p>
  </li>
</ul>

<h2 id="testing-fast-eigenvector-code">Testing Fast Eigenvector Code</h2>

<p>When I ran both the python and the fast code without the normalization of the time-series. I get the same results in both datasets. However, with normalization of the timeseries, I get different results. One suggestion from Steve was that there might be a difference in some normalization.</p>

<p>Details of my simplified comparison can be found on https://gist.github.com/czarrar/7950474 and at the bottom of the post.</p>

<h2 id="abide">ABIDE</h2>

<p>Let’s first make a table and workflow explaining everything. I’ll add it here first and then move it to another spot later.</p>

<p>I was able to start the processing for degree centrality with our dataset. I should be able to…</p>

<h2 id="gist">Gist</h2>

<p><div><script src='https://gist.github.com/7950474.js'></script>
<noscript><pre><code>import numpy as np
from CPAC.cwas.subdist import norm_cols
from fast_ecm import fast_eigenvector_centrality # this is from the other gist; can ignore this and paste in the other function

print 'Compare with non-normalized matrices'

m  = np.random.random((200,1000))
cm = m.T.dot(m)

# Let's first call a basic approach
# This actually doesn't work, not sure what I'm setting wrong
from scipy import linalg as LA
w01,v01 = LA.eigh(cm, eigvals=(0,0))
e01     = cm.dot(np.abs(v01))/w01[0]

# Let's call a second basic approach (used currently)
from scipy.sparse import linalg as sLA
w02,v02 = sLA.eigsh(cm, k=1, which='LM', maxiter=1000)
e02     = cm.dot(np.abs(v02))/w02[0]

# Finally let's call the fast eigenvector (power approach)
v03     = fast_eigenvector_centrality(m, verbose=False)

# How different are the second and third ones?
print 'mean absolute diff: ', np.abs(e02-v03).mean()
print 'correlation: ', np.corrcoef(e02.T, v03.T)[0,1]



print 'Compare with normalized matrices'

n  = norm_cols(m)
cn = n.T.dot(n)

# Let's first call a basic approach
from scipy import linalg as LA
w11,v11 = LA.eigh(cn, eigvals=(0,0))
e11     = cn.dot(np.abs(v11))/w11[0]

# Let's call a second basic approach (used currently)
from scipy.sparse import linalg as sLA
w12,v12 = sLA.eigsh(cn, k=1, which='LM', maxiter=1000)
e12     = cn.dot(np.abs(v12))/w12[0]

# Finally let's call the fast eigenvector (power approach)
v13     = fast_eigenvector_centrality(n, verbose=False)

# How different are the second and third ones?
print 'mean absolute diff: ', np.abs(e12-v13).mean()
print 'correlation: ', np.corrcoef(e12.T, v13.T)[0,1]
</code></pre></noscript></div>
</p>
]]></content>
  </entry>
  
</feed>
