<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: quickpack | Zarrar's Journaling]]></title>
  <link href="http://czarrar.github.io/blog/categories/quickpack/atom.xml" rel="self"/>
  <link href="http://czarrar.github.io/"/>
  <updated>2013-12-09T20:11:39-05:00</updated>
  <id>http://czarrar.github.io/</id>
  <author>
    <name><![CDATA[Zarrar Shehzad]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[More Quick Pack Testing]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/18/more-quick-pack-testing/"/>
    <updated>2013-11-18T14:01:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/18/more-quick-pack-testing</id>
    <content type="html"><![CDATA[<h2 id="changing-generation-of-yaml-file">Changing generation of yaml file</h2>

<p>I first worked on correcting the generation of the yml file with the file paths to the intermediate CPAC outputs from another run. I had to move away from using the symlinks folder to the sink folder due to errors in the symlinks folder. This might have also been a good move since hopefully it will make it easier for me to generate a quick pack file for Pierre and Xinian’s data.</p>

<p>Here is the new function that will build the file path to the intermediate files:</p>

<p>``` python
def build_file_path(init_dir, path_suffixes, templ):
    # Iterate through path suffixes, only keeping paths that exist
    if not isinstance(path_suffixes, list):
        path_suffixes = [path_suffixes]
    file_path = []
    for path_suffix in path_suffixes:
        file_path = file_path + glob(op.join(init_dir, path_suffix % templ))</p>

<pre><code>if len(file_path) &gt; 1:
    print "WARNING: Currently only one file for '%s' is supported" % file_path
    print "Choosing first one '%s'" % file_path[0]
    file_path = file_path[0]
elif len(file_path) == 0:
    file_path = ""
else:
    file_path = file_path[0]
return file_path ```
</code></pre>

<h3 id="sample-yaml-output">Sample Yaml Output</h3>

<p>There’s a bunch of other code that I can get into later but here’s some output from one pipeline and strategy. This is from simply running <code>gen_quick_pack.py</code> in the <code>/home2/data/Projects/ABIDE_Initiative/CPAC/abide/config/test_quick_pack</code> folder.</p>

<p><code>
- anat: /data/Projects/ABIDE_Initiative/CPAC/RawData/Caltech/0051466/session_1/anat_1/mprage.nii.gz
  anatomical_brain: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/anatomical_brain/mprage_RPI_3dc.nii.gz
  anatomical_reorient: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/anatomical_reorient/mprage_RPI.nii.gz
  anatomical_to_mni_nonlinear_xfm: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/anatomical_to_mni_nonlinear_xfm/ants_Warp.nii.gz
  ants_affine_xfm: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/ants_affine_xfm/ants_Affine.txt
  functional_brain_mask: {rest_1_rest: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/functional_brain_mask/_scan_rest_1_rest/rest_3dc_tshift_RPI_3dv_automask.nii.gz}
  functional_brain_mask_to_standard: {rest_1_rest: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/functional_brain_mask_to_standard/_scan_rest_1_rest/rest_3dc_tshift_RPI_3dv_automask_wimt.nii.gz}
  functional_freq_filtered: {rest_1_rest: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/functional_nuisance_residuals/_scan_rest_1_rest/_csf_threshold_0.96/_gm_threshold_0.7/_wm_threshold_0.96/_compcor_ncomponents_5_selector_pc10.linear1.wm0.global0.motion1.quadratic1.gm0.compcor1.csf0/residual.nii.gz}
  functional_mni: {rest_1_rest: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/functional_mni/_scan_rest_1_rest/_csf_threshold_0.96/_gm_threshold_0.7/_wm_threshold_0.96/_compcor_ncomponents_5_selector_pc10.linear1.wm0.global0.motion1.quadratic1.gm0.compcor1.csf0/residual_wtsimt.nii.gz}
  functional_nuisance_residuals: {rest_1_rest: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/functional_nuisance_residuals/_scan_rest_1_rest/_csf_threshold_0.96/_gm_threshold_0.7/_wm_threshold_0.96/_compcor_ncomponents_5_selector_pc10.linear1.wm0.global0.motion1.quadratic1.gm0.compcor1.csf0/residual.nii.gz}
  functional_to_anat_linear_xfm: {rest_1_rest: ''}
  mean_functional: {rest_1_rest: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/mean_functional/_scan_rest_1_rest/rest_3dc_tshift_RPI_3dv_3dc_3dT.nii.gz}
  mni_normalized_anatomical: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/mni_normalized_anatomical/ants_deformed.nii.gz
  preprocessed: {rest_1_rest: /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/preprocessed/_scan_rest_1_rest/rest_3dc_tshift_RPI_3dv_3dc_maths.nii.gz}
  rest: {rest_1_rest: /data/Projects/ABIDE_Initiative/CPAC/RawData/Caltech/0051466/session_1/rest_1/rest.nii.gz}
  scan_parameters: {acquisition: alt+z, first_tr: '0', last_tr: None, reference: '17',
    tr: '2'}
  subject_id: '0051466'
  unique_id: session_1
</code></p>

<h2 id="first-wave-of-testing-using-alff">First Wave of Testing using ALFF</h2>

<p>Now I am trying to test the running of CPAC for the various derivatives using the quick pack generated files like that above. I run quick pack using the following command <code>run_quick_pack.py</code>. I ran the quick pack using inputs where there was no filtering but there was global signal correction.</p>

<p><strong>nofilt_global</strong></p>

<h3 id="first-run">First Run</h3>

<p>I did get an error that ended up being a missing path for <code>functional_to_anat_linear_xfm.mat</code>. I added a warning to deal with a future empty path. I also fixed the path.</p>

<h3 id="second-run">Second Run</h3>

<p>Trying my hand again, it ran smoothly! Woot woot. But wait.</p>

<h3 id="third-run">Third Run</h3>

<p>Ok this time it should be good. I noticed one mistake where for my paths I had inverted global and no global correction. Quick redo and stuff again appears to have run smoothly.</p>

<h3 id="testing">Testing</h3>

<p>I will run the following file in R <code>/home2/data/Projects/ABIDE_Initiative/CPAC/abide/tests/quickpack/compare_10_alff.R</code>.</p>

<p>This was all good.</p>

<h2 id="other-tests">Other Tests</h2>

<p>The tests for all the other derivatives were all good. So we are good to move forward.</p>

<h2 id="next-steps">Next Steps</h2>

<p>This isn’t really meant for this section but the next items for ABIDE and QuickPack are</p>

<ul>
  <li>Fix QC Pages</li>
  <li>Check QC output from Yang</li>
  <li>
    <p>Do the QC</p>
  </li>
  <li>
    <p>Look at the centrality code and make more efficient if possible</p>
  </li>
  <li>Copy the other data into a new directory</li>
  <li>Create new generate quick pack scripts for the new data</li>
</ul>

<h2 id="confirming-input-to-centrality">Confirming input to centrality</h2>

<p>Also should be moved to a different page. But I have confirmed that the centrality node uses the functional data from standard space and at the very least the 4D functional data must be in the same space as the prior mask.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Quick Pack]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/15/testing-quick-pack/"/>
    <updated>2013-11-15T15:41:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/15/testing-quick-pack</id>
    <content type="html"><![CDATA[<p>Today, I want to test my different quick pack results with the combined preprocessing + derivates run.</p>

<p>Note that the files for running the preprocessing and derivatives are located in <code>/home2/data/Projects/ABIDE_Initiative/CPAC/abide/config/test_quick_pack</code>.</p>

<p>The files for testing the outputs are in <code>/home2/data/Projects/ABIDE_Initiative/CPAC/abide/tests/quickpack</code>.</p>

<h2 id="failed-comparison">Failed Comparison</h2>

<p>My first run at comparing the ALFF/REHO results failed. So now I’m figuring out what was different in their inputs (assuming that actual computation was the same).</p>

<p>The complete CPAC run uses that following as input for REHO:</p>

<p><code>/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Working/resting_preproc_0051466_session_1/nuisance_0/_scan_rest_1_rest/_csf_threshold_0.96/_gm_threshold_0.7/_wm_threshold_0.96/_compcor_ncomponents_5_selector_pc10.linear1.wm0.global1.motion1.quadratic1.gm0.compcor1.csf0/residuals/residual.nii.gz</code></p>

<p>So here it appears there is no frequency filtering that was applied. However, it appears the input used in the reho quick pack is not the same although the path looks similar:</p>

<p><code>/home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/sym_links/pipeline_MerrittIsland/_compcor_ncomponents_5_linear1.global1.motion1.quadratic1.compcor1.CSF_0.96_GM_0.7_WM_0.96/0051466_session_1/scan_rest_1_rest/func/functional_nuisance_residuals.nii.gz</code></p>

<p>Now since the above file is in the symlinks directory, I found out the original file and it appears it points to a nuisance residuals that has not had global correction.</p>

<p><code>/home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_MerrittIsland/0051466_session_1/functional_nuisance_residuals/_scan_rest_1_rest/_csf_threshold_0.96/_gm_threshold_0.7/_wm_threshold_0.96/_compcor_ncomponents_5_selector_pc10.linear1.wm0.global0.motion1.quadratic1.gm0.compcor1.csf0/residual.nii.gz</code></p>

<p>If I use the global1 version of things, the files used with All_Output and Reho_Output are now the same. This implies that the symlinks for All_Output should not be used. So for now use only the working directory outputs!!! I should be able to guess these from the sink outputs?</p>

<h2 id="test-1">Test 1</h2>

<script type="math/tex; mode=display"> \sqrt{2*(1-r)} </script>

<h3 id="greater-test">Greater Test</h3>

<p>Match - Game - Point</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Solving Quick Pack]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/13/solving-quick-pack/"/>
    <updated>2013-11-13T12:04:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/13/solving-quick-pack</id>
    <content type="html"><![CDATA[<h1 id="running-alff">Running ALFF</h1>

<p>It all appears to run fine except one link node.</p>

<p><code>
131113-12:02:04,683 workflow ERROR:                                                                                                                                     [575/9353]
         ['Node link_16.a0 failed to run on host rocky.']
131113-12:02:04,684 workflow INFO:
         Saving crash info to /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/crash/crash-20131113-120204-milham-link_16.a0.npz
131113-12:02:04,685 workflow INFO:
         Traceback (most recent call last):
  File "/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages/nipype/pipeline/plugins/multiproc.py", line 18, in r
un_node
    result['result'] = node.run(updatehash=updatehash)
  File "/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages/nipype/pipeline/engine.py", line 1282, in run
    self._run_interface()
  File "/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages/nipype/pipeline/engine.py", line 1380, in _run_inter
face
    self._result = self._run_command(execute)
  File "/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages/nipype/pipeline/engine.py", line 1504, in _run_comma
nd
    result = self._interface.run()
  File "/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages/nipype/interfaces/base.py", line 895, in run
    runtime = self._run_interface(runtime)
  File "/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages/nipype/interfaces/utility.py", line 412, in _run_int
erface
    out = function_handle(**args)
  File "&lt;string&gt;", line 16, in prepare_symbolic_links
  File "/home2/data/Projects/CPAC_Regression_Test/2013-05-30_cwas/C-PAC/CPAC/utils/utils.py", line 562, in create_symbolic_links
    ext = fname.split('.', 1)[1]
IndexError: list index out of range
Interface Function failed to run. 
</code></p>

<p>The error occurs because a path without a file is passed. It’s a little unclear why this link is even being run? Let’s get some background straight.</p>

<h1 id="what-is-sinked-and-linked">What is sinked and linked?</h1>

<p>So we can see what’s being synced with the following line of code towards the end:</p>

<p><code>python
for strat in strat_list:
	rp = strat.get_resource_pool()
</code></p>

<p>The variable <code>rp</code> is basically a dictionary with the key being a node name (e.g., <code>functional_mni</code>) and the value being a tuple with the actual node and the actual out_file. With my run of ALFF, below are the values of rp:</p>

<p><code>
{'alff_Z_img': (resting_preproc_0051466_session_1.alff_falff_0,
  'outputspec.alff_Z_img'),
 'alff_Z_smooth': (resting_preproc_0051466_session_1.alff_Z_smooth_0,
  'out_file'),
 'alff_Z_to_standard': (resting_preproc_0051466_session_1.alff_Z_to_standard_0,
  'outputspec.out_file'),
 'alff_Z_to_standard_smooth': (resting_preproc_0051466_session_1.alff_Z_to_standard_smooth_0,
  'out_file'),
 'alff_img': (resting_preproc_0051466_session_1.alff_falff_0,
  'outputspec.alff_img'),
 'anatomical_brain': (resting_preproc_0051466_session_1.anatomical_brain_gather_0,
  'outputspec.anat'),
 'anatomical_reorient': (anatomical_reorient_gather_0, 'outputspec.anat'),
 'anatomical_to_mni_nonlinear_xfm': (resting_preproc_0051466_session_1.anatomical_to_mni_nonlinear_xfm_gather_0,
  'outputspec.anat'),
 'ants_affine_xfm': (resting_preproc_0051466_session_1.ants_affine_xfm_gather_0,
  'outputspec.anat'),
 'falff_Z_img': (resting_preproc_0051466_session_1.alff_falff_0,
  'outputspec.falff_Z_img'),
 'falff_Z_smooth': (resting_preproc_0051466_session_1.falff_Z_smooth_0,
  'out_file'),
 'falff_Z_to_standard': (resting_preproc_0051466_session_1.falff_Z_to_standard_0,
  'outputspec.out_file'),
 'falff_Z_to_standard_smooth': (resting_preproc_0051466_session_1.falff_Z_to_standard_smooth_0,
  'out_file'),
 'falff_img': (resting_preproc_0051466_session_1.alff_falff_0,
  'outputspec.falff_img'),
 'functional_brain_mask': (resting_preproc_0051466_session_1.functional_brain_mask_gather_0,
  'outputspec.rest'),
 'functional_brain_mask_to_standard': (resting_preproc_0051466_session_1.functional_brain_mask_to_standard_gather_0,
  'outputspec.rest'),
 'functional_freq_filtered': (resting_preproc_0051466_session_1.functional_freq_filtered_gather_0,
  'outputspec.rest'),
 'functional_mni': (functional_mni_gather_0, 'outputspec.rest'),
 'functional_nuisance_residuals': (resting_preproc_0051466_session_1.functional_nuisance_residuals_gather_0,
  'outputspec.rest'),
 'functional_to_anat_linear_xfm': (resting_preproc_0051466_session_1.functional_to_anat_linear_xfm_gather_0,
  'outputspec.rest'),
 'mean_functional': (mean_functional_gather_0, 'outputspec.rest'),
 'mni_normalized_anatomical': (resting_preproc_0051466_session_1.mni_normalized_anatomical_gather_0,
  'outputspec.anat'),
 'preprocessed': (resting_preproc_0051466_session_1.preprocessed_gather_0,
  'outputspec.rest')}
</code></p>

<p>With that in mind, we can try to understand for the link error, what’s the related node. It appears that it is related to the functional_freq_filtered node name as the input path for linking is <code>/home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/ALFF_Output/pipeline_me/0051466_session_1/functional_freq_filtered/_scan_rest_1_rest/sinker_16</code>.</p>

<p>Since the actually input files like functional_freq_filtered are not copied into the working directory, the sink and link will not work as there is nothing to sink/link from the working directory. How can I tackle this issue?</p>

<ul>
  <li>I could create a workaround to not run sinking/linking for these particular strategies. For instance if preprocessing or what not were not turned on.</li>
  <li>In my get_func… function, I could do a soft-link inside the current directory. However this would need to be a second step, no?</li>
</ul>

<h1 id="issues">Issues</h1>

<h2 id="fix-error">Fix Error</h2>

<p>Spoke to Cameron and will be creating an exclusion or stop list. I’m thinking that as I’m adding the particular files to the strategy pool, I want to add the node name to an exclusion list as well. Yup these set of changes got it going.</p>

<h2 id="symlinks-error">Symlinks Error</h2>

<p>After fixing the prior issue, I then noticed that the symlinks directory is sort-of weird. There’s a lot of repetition. For instance, here are some of the main directories: </p>

<ul>
  <li>scan_rest<em>1_rest_rest</em>1_rest </li>
  <li>scan_rest<em>1_rest_rest</em>1<em>rest_rest</em>1_rest</li>
  <li>scan_rest<em>1_rest_rest</em>1<em>rest_rest</em>1<em>rest_rest</em>1_rest</li>
</ul>

<p>One of these directories as the alff/falff output for native space and with/without smoothing. The second is the output in standard space while the third is the same thing but with smoothing. A little obtuse.</p>

<p>The sink directory on the other hand is fairly normal and easy to work through. So my current thought is to simply use this going forward and make my own symlinks generation script.</p>

<h2 id="duplicate-montage-node-name">Duplicate Montage Node Name</h2>

<p>If I try a config file with all the preprocessing or even one for just alff, I get a similar error.</p>

<p>```
Traceback (most recent call last):
  File “/home2/dlurie/Canopy/appdata/canopy-1.0.3.1262.rh5-x86<em>64/lib/python2.7/multiprocessing/process.py”, line 258, in _bootstrap
    self.run()
  File “/home2/dlurie/Canopy/appdata/canopy-1.0.3.1262.rh5-x86</em>64/lib/python2.7/multiprocessing/process.py”, line 114, in run
    self.<em>target(*self._args, **self._kwargs)
  File “/home2/data/Projects/CPAC_Regression_Test/2013-05-30_cwas/C-PAC/CPAC/pipeline/cpac_pipeline.py”, line 3649, in prep_workflow
    montage_mni_anat, ‘inputspec.underlay’)
  File “/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages/nipype/pipeline/engine.py”, line 306, in connect
    self._check_nodes(newnodes)
  File “/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages/nipype/pipeline/engine.py”, line 772, in _check_nodes
    raise IOError(‘Duplicate node name %s found.’ % node.name)
IOError: Duplicate node name montage_mni_anat</em>0 found.
``</p>

<p>So let’s try to play with the code to see what is going on here. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tuesday]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/05/tuesday/"/>
    <updated>2013-11-05T15:26:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/05/tuesday</id>
    <content type="html"><![CDATA[<h1 id="nilearn">NiLearn</h1>

<p>I need to regenerate the 4D output. I previously used data with nuisance co-variates removed, however I should have used the data prior to nuisance correction. Remember the data’s location<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>.</p>

<p>So again I want to turn off nuisance correction and bandpass filtering. In order to do this, I’m rerunning (on top of the old) the participants with nuisance and bandpass turned off.</p>

<p>Checking on the preprocessing, it initially skipped a bunch of things but now seems to be running some initial steps again. If this takes too long (i.e., is still going into tomorrow), then I might try to apply the warp myself tomorrow.</p>

<hr />

<h1 id="abide">ABIDE</h1>

<p>Since the QC pages have been fixed, I started to re-run the ABIDE analysis. This time I used 6mm of smoothing, added back the degree centrality, and running each subject with 4 cores on gelert. It is running strong (for now). There are 1102 subjects to run and currently 62 are being run in parallel.</p>

<hr />

<h1 id="emotional-bs">Emotional BS</h1>

<p>I ran the preprocessing for these participants before the QC issue for CPAC was fixed. Now I want to rebuild just the QC as follows:</p>

<p>``` python
import sys
sys.path.insert(0, ‘/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages’)
sys.path.insert(1, “/home/milham/Downloads/cpac_master”)</p>

<p>import CPAC
CPAC.utils.create_all_qc.run(‘/home2/data/Projects/Emotional-BS/processed_data’)
```</p>

<p>This does work but I then later noticed that I used 4.5mm as the smoothness instead of 6mm. I may need to rerun this down the line? Since for now this only effects derivatives, which I’m not really using, then this shouldn’t be an issue.</p>

<p>I also looked into co-registering the two anatomicals. I ended up dropping this endeavor for now since the gain in SNR and benefit to any results should not be too great. In looking at the QC, one possibility is that we may want to replace one of our anatomicals with the other anatomical.</p>

<h2 id="multi-instance-learning">Multi-Instance Learning</h2>

<p>I did a basic search for relevant reading material. I found the following:</p>

<p><em>A paper outlining the approach in a seemingly easy manner.</em>
http://pages.ucsd.edu/~ztu/courses/2013_CS_spring/reading/bbabenko_re.pdf</p>

<p><em>Very detailed slides that appear to give a good overview.</em>
http://www.cs.columbia.edu/~andrews/pub/talk-proposal-july8-clean.pdf</p>

<p><em>Two links with relevant python code</em><br />
http://engr.case.edu/doran_gary/code.html<br />
https://github.com/garydoranjr/misvm</p>

<hr />

<h1 id="todo">TODO</h1>

<p><code>
[] NiLearn Test Data
	[x] Sent email confirming that band-pass filtering is required
	[] Get the pre-nuisance variables
[x] ABIDE Preprocessing
	[x] Restart the preprocessing using 4 cores (everything except eigen)
[x] Emotional BS
	[x] Try to regenerate the QC pages based on current output
	[x] Lookup some multi-instance learning stuff
	[] QC
[] QuickPack
	[] ? (not enough time today to make substantial progress)
</code></p>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><code>/home2/data/Projects/CPAC_Regression_Test/2013-10-04_v0-3-2/run/gael-o/package</code><a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monday]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/04/monday/"/>
    <updated>2013-11-04T12:20:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/04/monday</id>
    <content type="html"><![CDATA[<h1 id="nilearn-test-data">NiLearn Test Data</h1>

<p>Note that the code to generate all this is as well as the actual package is in <code>/home/data/Projects/CPAC_Regression_Test/2013-10-04_v0-3-2/run/gael-o/package</code>.</p>

<p>I’ve already gotten the subject data and regressors. I am left to create the group phenotypic file. It appears that I don’t need to duplicate the previous setup so I can use what we have on motion per subject. With this new data packaged up, I uploaded it to my connectir repository as I still don’t have access to the ADHD200 repository.</p>

<p>The download links are below:</p>

<p>http://connectir.projects.nitrc.org/adhd40_p1.nii.gz
http://connectir.projects.nitrc.org/adhd40_p2.nii.gz
http://connectir.projects.nitrc.org/adhd40_p3.nii.gz
http://connectir.projects.nitrc.org/adhd40_p4.nii.gz</p>

<p>And I have contacted the other peeps about this. So DONE.</p>

<hr />

<h1 id="abide-preprocessing">ABIDE Preprocessing</h1>

<p>I found out that the QC pages are a little broken. So this will have to wait.</p>

<h2 id="run-config-setup">Run Config Setup</h2>

<p>I have adjusted this file to run one subject for every two nodes. I am using FSL5 now. Preprocessing will be run as well as all the derivatives except centrality (degree or eigen). This is because they both need a decent amount of RAM and computational time so I’ll wait to run them separately later.</p>

<hr />

<h1 id="quickpack">QuickPack</h1>

<p>So the first general issue that I’m experiencing is that if I run everything (no quick-pack), then I don’t get any of the sym links. However, in my Emotional-BS run, the symlinks all seem to be fine! A little weird. I’m not sure what is causing the problem.</p>

<h2 id="running-with-just-cpac">Running with just CPAC</h2>

<p>I’m focusing on why I’m getting symlink issues when I run internally with CPAC. I think the reasons that no files are being symlinked is because there might be single quotes in the strategy part of the path.</p>

<p><code>bash
ln -s /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_RameyBorough/0051466_session_1/qc/mni_normalized_anatomical_a/mni_anat_a.png /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/sym_links/pipeline_RameyBorough/_compcor_'ncomponents_5_linear1.global1.motion1.quadratic1.compcor1.csf0'_CSF_0.96_GM_0.7_WM_0.96/0051466_session_1/scan/qc/mni_anat_a.png
</code></p>

<p>If I run this command that was spit out from CPAC, then I get a “No such file or directory” error. This error doesn’t appear with CPAC but this might explain why no symlinks were generated.</p>

<p>Now we must understand why those single quotes are there. We should note that there were actually 2 strategies that I had given but only one strategy folder in the symlinks directory folder was created. I wonder if this has to do with some error?</p>

<p>I tried to open the config file with the GUI and re-save it, seeing if that would help but it didn’t. Now I’ll try to run the pipeline from the GUI. Yup that fixed the issue and it isn’t related to the fact that I’m using Dan’s path and shiz. Running this one subject through the GUI.</p>

<h2 id="running-alff">Running ALFF</h2>

<p>There was one previous and confusing link issue. However, another issue that I didn’t notice was the ALFF output directory using single quotes in its symlinks strategy directory and only has one of the two strategies. This suggests a potential benefit in running this through the GUI.</p>

<h3 id="gui">GUI</h3>

<p>This run failed. The error message is below. I am not sure what’s going on.</p>

<p><code>
Invalid Connection: ALFF: 0  resource_pool:  {}
Process Process-3:
Traceback (most recent call last):
  File "/home2/dlurie/Canopy/appdata/canopy-1.0.3.1262.rh5-x86_64/lib/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/home2/dlurie/Canopy/appdata/canopy-1.0.3.1262.rh5-x86_64/lib/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/home2/dlurie/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/CPAC/pipeline/cpac_pipeline.py", line 1198, in prep_workflow
    alff, 'inputspec.rest_res')
  File "/home2/dlurie/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/nipype/pipeline/engine.py", line 306, in connect
    self._check_nodes(newnodes)
  File "/home2/dlurie/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/nipype/pipeline/engine.py", line 769, in _check_nodes
    if node.name in node_names:
AttributeError: 'NoneType' object has no attribute 'name'
</code></p>

<h3 id="cli">CLI</h3>

<p>The error on the command-line is driven in part by two correction strategies (with and without global). Since my quick pack, can’t really do both of those strategies at once anyway, why not just have one strategy specified. Trying this with ALFF and that didn’t work! Ugh so it’s specifically related to the command-line, which is doing something differently than the GUI.</p>

<hr />

<h1 id="emotional-bs">Emotional-BS</h1>

<p>The preprocessing is done but the QC pages were not generated due to some issue in CPAC. I wish there was some way of running the QC scripts with the current outputs without me having to re-run all of CPAC. Since I ran via gelert using the <code>/tmp</code> directory, it will also need to redo all the processing.</p>

<hr />

<h1 id="random">Random</h1>

<p>I spent a bit of time getting the table of contents to work on these pages. Hopefully it was worth it (I might want to also add a go back to the top link for each header). At the very least it gives a sort-of summary list of what will be on the post.</p>

<p>I think I also had a bit of trouble keeping on track today. It was very frustrating and I’m hoping it was just re-adjusting to coming back to work after a brief break.</p>

<hr />

<h1 id="todo">TODO</h1>

<p><code>
[x] NiLearn Test Data
	[x] Generate group phenotype file
[] ABIDE Preprocessing
	[x] Email Cam about next steps
	[x] Setup the pipeline with gelert excluding centrality
	[] Start running the pipeline
[] QuickPack
	[x] Check that complete run was good
	[x] Try to figure out why the old runs did fine?
	[] Using the new complete run as input for QP
</code></p>
]]></content>
  </entry>
  
</feed>
