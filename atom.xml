<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Zarrar's Journaling]]></title>
  <link href="http://czarrar.github.io/atom.xml" rel="self"/>
  <link href="http://czarrar.github.io/"/>
  <updated>2013-11-05T21:45:35-05:00</updated>
  <id>http://czarrar.github.io/</id>
  <author>
    <name><![CDATA[Zarrar Shehzad]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rerunning CWAS using Transformed Correlations]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/05/rerunning-cwas-using-transformed-correlations/"/>
    <updated>2013-11-05T20:26:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/05/rerunning-cwas-using-transformed-correlations</id>
    <content type="html"><![CDATA[<p>We had previously been using the semi-metric <code>1-r</code>, however are now with a reviewer&rsquo;s suggestion switching to a metric using a slight transformation of the prior person correlation <code>sqrt(2*1-r)</code><sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>. This change although simple will require a massive effort to semi-reanalyze everything.</p>

<h1>Code</h1>

<p>The first order of business is creating a function that easily transforms my big matrices and re-generates the gower centered matrices. A few nuances is that I need to make sure to set the number of threads to use in advance (otherwise all processors will be occupied) and to set the memory limit for gower centering.</p>

<p>The actual command can be called from bash with the following usage:</p>

<p><code>./transform_cor.R distance-descriptor memlimit nthreads</code></p>

<ul>
<li><em>distance-descriptor</em>: File path to the subject distances descriptor</li>
<li><em>memlimit</em>: Upper bound on RAM to use</li>
<li><em>nthreads</em>: Number of threads to use for matrix algebra operations</li>
</ul>


<h1>Normandy (aka Redoing Almost All Figures)</h1>

<h2>What Figures</h2>

<p>Below are the list of figures in the main paper and whether I need to redo it or not.</p>

<ol>
<li><strong>Yes</strong> Since this is an example figure, I don&rsquo;t think I need to redo the particular analysis. However, I do need to edit the figure so it shows <code>sqrt(2*(1-r))</code>.</li>
<li><strong>No</strong> Just a table.</li>
<li><strong>Yes</strong> Redo 2 analyses and 3 surface maps.</li>
<li><strong>Yes</strong> Redo 2 analyses and 2 histograms.</li>
<li><strong>Yes</strong> Redo network summary and surface map.</li>
<li><strong>Yes</strong> Redo 3 surface maps.</li>
<li><strong>Yes</strong> Redo 6 analyses and 6 surface maps.</li>
<li><strong>Yes</strong> Redo 2 scatter plots, 2 analyses, and 4 surface maps.</li>
<li><strong>Yes</strong> Redo 2 bar plots.</li>
<li><strong>Yes</strong> Redo 3 analyses, 3 surface maps, and 3 network summaries.</li>
<li><strong>Yes</strong> Redo 4 analyses and 4 surface maps.</li>
<li><strong>Yes</strong> Redo 3 analyses and 4 surface maps.</li>
</ol>


<p>Supplementary Figures</p>

<ol>
<li><strong>Yes</strong> 3 analyses, 3 surface maps, and 2 scatter plots.</li>
<li><strong>Yes</strong> ?</li>
<li><strong>Yes</strong> 2 analyses and 2 surface maps.</li>
<li><strong>Yes</strong> 6 analyses and 6 surface maps.</li>
<li><strong>Yes</strong> 3 analyses and 3 surface maps.</li>
<li><strong>Yes</strong> 3+ analyses and 3 plots.</li>
</ol>

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>I am still working on getting latex to work so these math equations will be not be displayed well for now.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tuesday]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/05/tuesday/"/>
    <updated>2013-11-05T15:26:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/05/tuesday</id>
    <content type="html"><![CDATA[<h1>NiLearn</h1>

<p>I need to regenerate the 4D output. I previously used data with nuisance co-variates removed, however I should have used the data prior to nuisance correction. Remember the data&rsquo;s location<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>.</p>

<p>So again I want to turn off nuisance correction and bandpass filtering. In order to do this, I&rsquo;m rerunning (on top of the old) the participants with nuisance and bandpass turned off.</p>

<p>Checking on the preprocessing, it initially skipped a bunch of things but now seems to be running some initial steps again. If this takes too long (i.e., is still going into tomorrow), then I might try to apply the warp myself tomorrow.</p>

<hr />

<h1>ABIDE</h1>

<p>Since the QC pages have been fixed, I started to re-run the ABIDE analysis. This time I used 6mm of smoothing, added back the degree centrality, and running each subject with 4 cores on gelert. It is running strong (for now). There are 1102 subjects to run and currently 62 are being run in parallel.</p>

<hr />

<h1>Emotional BS</h1>

<p>I ran the preprocessing for these participants before the QC issue for CPAC was fixed. Now I want to rebuild just the QC as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'><span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s">&#39;/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s">&quot;/home/milham/Downloads/cpac_master&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">CPAC</span>
</span><span class='line'><span class="n">CPAC</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">create_all_qc</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s">&#39;/home2/data/Projects/Emotional-BS/processed_data&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>This does work but I then later noticed that I used 4.5mm as the smoothness instead of 6mm. I may need to rerun this down the line? Since for now this only effects derivatives, which I&rsquo;m not really using, then this shouldn&rsquo;t be an issue.</p>

<p>I also looked into co-registering the two anatomicals. I ended up dropping this endeavor for now since the gain in SNR and benefit to any results should not be too great. In looking at the QC, one possibility is that we may want to replace one of our anatomicals with the other anatomical.</p>

<h2>Multi-Instance Learning</h2>

<p>I did a basic search for relevant reading material. I found the following:</p>

<p><em>A paper outlining the approach in a seemingly easy manner.</em>
<a href="http://pages.ucsd.edu/~ztu/courses/2013_CS_spring/reading/bbabenko_re.pdf">http://pages.ucsd.edu/~ztu/courses/2013_CS_spring/reading/bbabenko_re.pdf</a></p>

<p><em>Very detailed slides that appear to give a good overview.</em>
<a href="http://www.cs.columbia.edu/~andrews/pub/talk-proposal-july8-clean.pdf">http://www.cs.columbia.edu/~andrews/pub/talk-proposal-july8-clean.pdf</a></p>

<p><em>Two links with relevant python code</em><br/>
<a href="http://engr.case.edu/doran_gary/code.html  ">http://engr.case.edu/doran_gary/code.html  </a>
<a href="https://github.com/garydoranjr/misvm">https://github.com/garydoranjr/misvm</a></p>

<hr />

<h1>TODO</h1>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="p">[]</span> <span class="n">NiLearn</span> <span class="n">Test</span> <span class="n">Data</span>
</span><span class='line'>  <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="n">Sent</span> <span class="n">email</span> <span class="n">confirming</span> <span class="n">that</span> <span class="n">band</span><span class="o">-</span><span class="k">pass</span> <span class="n">filtering</span> <span class="ow">is</span> <span class="n">required</span>
</span><span class='line'>  <span class="p">[]</span> <span class="n">Get</span> <span class="n">the</span> <span class="n">pre</span><span class="o">-</span><span class="n">nuisance</span> <span class="n">variables</span>
</span><span class='line'><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="n">ABIDE</span> <span class="n">Preprocessing</span>
</span><span class='line'>  <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="n">Restart</span> <span class="n">the</span> <span class="n">preprocessing</span> <span class="n">using</span> <span class="mi">4</span> <span class="n">cores</span> <span class="p">(</span><span class="n">everything</span> <span class="k">except</span> <span class="n">eigen</span><span class="p">)</span>
</span><span class='line'><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="n">Emotional</span> <span class="n">BS</span>
</span><span class='line'>  <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="n">Try</span> <span class="n">to</span> <span class="n">regenerate</span> <span class="n">the</span> <span class="n">QC</span> <span class="n">pages</span> <span class="n">based</span> <span class="n">on</span> <span class="n">current</span> <span class="n">output</span>
</span><span class='line'>  <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="n">Lookup</span> <span class="n">some</span> <span class="n">multi</span><span class="o">-</span><span class="n">instance</span> <span class="n">learning</span> <span class="n">stuff</span>
</span><span class='line'>  <span class="p">[]</span> <span class="n">QC</span>
</span><span class='line'><span class="p">[]</span> <span class="n">QuickPack</span>
</span><span class='line'>  <span class="p">[]</span> <span class="err">?</span> <span class="p">(</span><span class="ow">not</span> <span class="n">enough</span> <span class="n">time</span> <span class="n">today</span> <span class="n">to</span> <span class="n">make</span> <span class="n">substantial</span> <span class="n">progress</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p><code>/home2/data/Projects/CPAC_Regression_Test/2013-10-04_v0-3-2/run/gael-o/package</code><a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bootstrap of IQ CWAS]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/04/bootstrap-of-iq-cwas/"/>
    <updated>2013-11-04T23:38:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/04/bootstrap-of-iq-cwas</id>
    <content type="html"><![CDATA[<p>As per one of the reviewer comments, I am assessing the reproducibility of CWAS with a bootstrap analysis. I am only examining the results from the IQ dataset and will be looking at both the scans.</p>

<h2>Analysis</h2>

<p>I conducted the CWAS as a plugin with the <code>boot</code> package. The actual code can be seen with the github gist at the end. Note that the boot package resamples with replacement.</p>

<p>After I got the p-values for each bootstrap, I (based on Phil&rsquo;s suggestion):</p>

<blockquote><p>present some sort of map indicating the proportion of times each voxel comes out as significant. This is similar to the &#8216;bootstrap inclusion frequency&#8217; proposed in these references below</p><p>Royston, P. and Sauerbrei, W. (2008). Multivariable Model-building: a pragmatic approach to regression analysis based on fractional polynomials for modeling continuous variables. Wiley.</p><p>Sauerbrei, W. and Schumacher, M. (1992). A bootstrap resampling procedure for model building: application to the Cox regression model. Statistics in Medicine 11 2093â€“2109.</p><footer><strong>Phil Reiss</strong></footer></blockquote>


<p>I was able to do these steps fairly easily.</p>

<h2>Plotting</h2>

<p>The basic plots can be found on <a href="http://rpubs.com/czarrar/cwas-bootstrap.">http://rpubs.com/czarrar/cwas-bootstrap.</a> <strong>TODO</strong>: I am still needing to work through the surface rendering.</p>

<h2>Code</h2>

<div><script src='https://gist.github.com/7164165.js?file=cwas_bootstrap.R'></script>
<noscript><pre><code>library(connectir)
library(boot)

# data = model
boot_mdmr &lt;- function(formula, data, indices, sdist, factors2perm) {
    ###
    # Distances
    ###
    
    # We need to sample the distances based on the indices
    # that is we will create a new set of distances with subject indices based on indices
    # This will also create a local copy of the big matrix
    cat(&quot;Subset of subjects in distances\n&quot;)
    sdist &lt;- filter_subdist(sdist, subs=indices)
    
    # Now we can gowerify
    cat(&quot;Gowerify\n&quot;)
    gmat &lt;- gower.subdist2(sdist)
    
    # Info
    nvoxs &lt;- ncol(gmat)
    nsubs &lt;- sqrt(nrow(gmat))
    nperms &lt;- 4999
    nfactors &lt;- 1
    
    
    ###
    # Calculate memory demands
    ###
    opts &lt;- list(verbose=TRUE, memlimit=20, blocksize=0, superblocksize=0)
    opts &lt;- get_mdmr_memlimit(opts, nsubs, nvoxs, nperms, nfactors)
    # this will give opts$blocksize and opts$superblocksize that will
    # limit total RAM usage to 20GB
    
    ###
    # Get the model ready
    ###
    
    cat(&quot;Subset of subjects in model\n&quot;)
    model &lt;- data.frame(data[indices,])
    
    
    ###
    # Call MDMR
    ###
    
    ret &lt;- mdmr(gmat, formula, model, nperms, factors2perm, 
                 superblocksize=opts$superblocksize, blocksize=opts$blocksize)
    
    -log10(ret$pvals[,]) # or should I just return p-values?
}


###
# Bootstrap ROI-based IQ Results
###

# Set parallel processing
nthreads &lt;- 8
set_parallel_procs(1, nthreads, TRUE)

# Read in the distances (using ROI-based distances and not voxelwise here)
#dpath &lt;- &quot;/home2/data/Projects/CWAS/nki/cwas/short/compcor_kvoxs_fwhm08_to_kvoxs_fwhm08/subdist.desc&quot;
dpath &lt;- &quot;/home2/data/Projects/CWAS/nki/cwas/short/compcor_only_rois_random_k0800/subdist.desc&quot;
sdist &lt;- attach.big.matrix(dpath)

# Read in the model
mpath &lt;- &quot;/home2/data/Projects/CWAS/share/nki/subinfo/40_Set1_N104/subject_info_with_iq_and_gcors.csv&quot;
model &lt;- read.csv(mpath)
model &lt;- subset(model, select=c(&quot;FSIQ&quot;, &quot;Age&quot;, &quot;Sex&quot;, &quot;short_meanFD&quot;))

# Set the formula
f     &lt;- ~ FSIQ + Age + Sex + short_meanFD

# Call
results &lt;- boot(data=model, statistic=boot_mdmr, R=500, formula=f, sdist=sdist, factors2perm=&quot;FSIQ&quot;)
</code></pre></noscript></div>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monday]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/04/monday/"/>
    <updated>2013-11-04T12:20:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/04/monday</id>
    <content type="html"><![CDATA[<h1>NiLearn Test Data</h1>

<p>Note that the code to generate all this is as well as the actual package is in <code>/home/data/Projects/CPAC_Regression_Test/2013-10-04_v0-3-2/run/gael-o/package</code>.</p>

<p>I&rsquo;ve already gotten the subject data and regressors. I am left to create the group phenotypic file. It appears that I don&rsquo;t need to duplicate the previous setup so I can use what we have on motion per subject. With this new data packaged up, I uploaded it to my connectir repository as I still don&rsquo;t have access to the ADHD200 repository.</p>

<p>The download links are below:</p>

<p><a href="http://connectir.projects.nitrc.org/adhd40_p1.nii.gz">http://connectir.projects.nitrc.org/adhd40_p1.nii.gz</a>
<a href="http://connectir.projects.nitrc.org/adhd40_p2.nii.gz">http://connectir.projects.nitrc.org/adhd40_p2.nii.gz</a>
<a href="http://connectir.projects.nitrc.org/adhd40_p3.nii.gz">http://connectir.projects.nitrc.org/adhd40_p3.nii.gz</a>
<a href="http://connectir.projects.nitrc.org/adhd40_p4.nii.gz">http://connectir.projects.nitrc.org/adhd40_p4.nii.gz</a></p>

<p>And I have contacted the other peeps about this. So DONE.</p>

<hr />

<h1>ABIDE Preprocessing</h1>

<p>I found out that the QC pages are a little broken. So this will have to wait.</p>

<h2>Run Config Setup</h2>

<p>I have adjusted this file to run one subject for every two nodes. I am using FSL5 now. Preprocessing will be run as well as all the derivatives except centrality (degree or eigen). This is because they both need a decent amount of RAM and computational time so I&rsquo;ll wait to run them separately later.</p>

<hr />

<h1>QuickPack</h1>

<p>So the first general issue that I&rsquo;m experiencing is that if I run everything (no quick-pack), then I don&rsquo;t get any of the sym links. However, in my Emotional-BS run, the symlinks all seem to be fine! A little weird. I&rsquo;m not sure what is causing the problem.</p>

<h2>Running with just CPAC</h2>

<p>I&rsquo;m focusing on why I&rsquo;m getting symlink issues when I run internally with CPAC. I think the reasons that no files are being symlinked is because there might be single quotes in the strategy part of the path.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ln -s /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/pipeline_RameyBorough/0051466_session_1/qc/mni_normalized_anatomical_a/mni_anat_a.png /home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/All_Output/sym_links/pipeline_RameyBorough/_compcor_<span class="s1">&#39;ncomponents_5_linear1.global1.motion1.quadratic1.compcor1.csf0&#39;</span>_CSF_0.96_GM_0.7_WM_0.96/0051466_session_1/scan/qc/mni_anat_a.png
</span></code></pre></td></tr></table></div></figure>


<p>If I run this command that was spit out from CPAC, then I get a &ldquo;No such file or directory&rdquo; error. This error doesn&rsquo;t appear with CPAC but this might explain why no symlinks were generated.</p>

<p>Now we must understand why those single quotes are there. We should note that there were actually 2 strategies that I had given but only one strategy folder in the symlinks directory folder was created. I wonder if this has to do with some error?</p>

<p>I tried to open the config file with the GUI and re-save it, seeing if that would help but it didn&rsquo;t. Now I&rsquo;ll try to run the pipeline from the GUI. Yup that fixed the issue and it isn&rsquo;t related to the fact that I&rsquo;m using Dan&rsquo;s path and shiz. Running this one subject through the GUI.</p>

<h2>Running ALFF</h2>

<p>There was one previous and confusing link issue. However, another issue that I didn&rsquo;t notice was the ALFF output directory using single quotes in its symlinks strategy directory and only has one of the two strategies. This suggests a potential benefit in running this through the GUI.</p>

<h3>GUI</h3>

<p>This run failed. The error message is below. I am not sure what&rsquo;s going on.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>Invalid Connection: ALFF: 0  resource_pool:  <span class="o">{}</span>
</span><span class='line'>Process Process-3:
</span><span class='line'>Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
</span><span class='line'>  File <span class="s2">&quot;/home2/dlurie/Canopy/appdata/canopy-1.0.3.1262.rh5-x86_64/lib/python2.7/multiprocessing/process.py&quot;</span>, line 258, in _bootstrap
</span><span class='line'>    self.run<span class="o">()</span>
</span><span class='line'>  File <span class="s2">&quot;/home2/dlurie/Canopy/appdata/canopy-1.0.3.1262.rh5-x86_64/lib/python2.7/multiprocessing/process.py&quot;</span>, line 114, in run
</span><span class='line'>    self._target<span class="o">(</span>*self._args, **self._kwargs<span class="o">)</span>
</span><span class='line'>  File <span class="s2">&quot;/home2/dlurie/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/CPAC/pipeline/cpac_pipeline.py&quot;</span>, line 1198, in prep_workflow
</span><span class='line'>    alff, <span class="s1">&#39;inputspec.rest_res&#39;</span><span class="o">)</span>
</span><span class='line'>  File <span class="s2">&quot;/home2/dlurie/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/nipype/pipeline/engine.py&quot;</span>, line 306, in connect
</span><span class='line'>    self._check_nodes<span class="o">(</span>newnodes<span class="o">)</span>
</span><span class='line'>  File <span class="s2">&quot;/home2/dlurie/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/nipype/pipeline/engine.py&quot;</span>, line 769, in _check_nodes
</span><span class='line'>    <span class="k">if </span>node.name in node_names:
</span><span class='line'>AttributeError: <span class="s1">&#39;NoneType&#39;</span> object has no attribute <span class="s1">&#39;name&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>CLI</h3>

<p>The error on the command-line is driven in part by two correction strategies (with and without global). Since my quick pack, can&rsquo;t really do both of those strategies at once anyway, why not just have one strategy specified. Trying this with ALFF and that didn&rsquo;t work! Ugh so it&rsquo;s specifically related to the command-line, which is doing something differently than the GUI.</p>

<hr />

<h1>Emotional-BS</h1>

<p>The preprocessing is done but the QC pages were not generated due to some issue in CPAC. I wish there was some way of running the QC scripts with the current outputs without me having to re-run all of CPAC. Since I ran via gelert using the <code>/tmp</code> directory, it will also need to redo all the processing.</p>

<hr />

<h1>Random</h1>

<p>I spent a bit of time getting the table of contents to work on these pages. Hopefully it was worth it (I might want to also add a go back to the top link for each header). At the very least it gives a sort-of summary list of what will be on the post.</p>

<p>I think I also had a bit of trouble keeping on track today. It was very frustrating and I&rsquo;m hoping it was just re-adjusting to coming back to work after a brief break.</p>

<hr />

<h1>TODO</h1>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="o">[</span>x<span class="o">]</span> NiLearn Test Data
</span><span class='line'>  <span class="o">[</span>x<span class="o">]</span> Generate group phenotype file
</span><span class='line'><span class="o">[]</span> ABIDE Preprocessing
</span><span class='line'>  <span class="o">[</span>x<span class="o">]</span> Email Cam about next steps
</span><span class='line'>  <span class="o">[</span>x<span class="o">]</span> Setup the pipeline with gelert excluding centrality
</span><span class='line'>  <span class="o">[]</span> Start running the pipeline
</span><span class='line'><span class="o">[]</span> QuickPack
</span><span class='line'>  <span class="o">[</span>x<span class="o">]</span> Check that <span class="nb">complete </span>run was good
</span><span class='line'>  <span class="o">[</span>x<span class="o">]</span> Try to figure out why the old runs did fine?
</span><span class='line'>  <span class="o">[]</span> Using the new <span class="nb">complete </span>run as input <span class="k">for </span>QP
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CWAS Computational Complexity]]></title>
    <link href="http://czarrar.github.io/blog/2013/11/03/cwas-computational-complexity/"/>
    <updated>2013-11-03T20:06:00-05:00</updated>
    <id>http://czarrar.github.io/blog/2013/11/03/cwas-computational-complexity</id>
    <content type="html"><![CDATA[<p>I&rsquo;m trying to address some reviewer questions regarding the computational complexity of CWAS and particularly the MDMR step.</p>

<p>In summary, the complexity (I think) is</p>

<ul>
<li>O(V*n<sup>2</sup>) for computing the distance matrices</li>
<li>O(k*n<sup>2</sup>) for creating the hat matrices</li>
<li>O(n<sup>3</sup>) for gower centering the distance matrices</li>
<li>O(Pxn<sup>2xV</sup>) for MDMR</li>
</ul>


<p>where V = # of voxels, n = # of subjects, k = # of regressors, P = # of permutations.</p>

<p>The real optimization is the final MDMR step, where the traditional MDMR approach is O(Pxn<sup>3xV</sup>) or O(n<sup>3</sup>) whereas ours is O(n<sup>2</sup>).</p>

<h1>About Time Complexity</h1>

<p>My first step here is to build up some knowledge about the computational time needed for computing the different steps. I searched the terms computational complexity and time complexity but could have also looked at Big-O Notation. It seems like time complexity is the most appropriate term.</p>

<p>Efficiency of an algorithm can be measured by [1]:</p>

<ul>
<li>Execution time (time complexity)</li>
<li>Amount of memory required (space complexity)</li>
</ul>


<p>Time complexity expresses the relationship between the size of the size of the input and the run time for the algorithm. There&rsquo;s other relevant information on the wiki page and some online slides [2,3].</p>

<h2>Complexity of Math Operations</h2>

<p>For measuring the complexity of individual operations, wikipedia has a great summary page [4]. Although it gives difference values for the elementary addition and multiplications, it seems one might assume they run in linear or quasi-linear time (based on other pages?). However, technically multiplication is n<sup>2</sup> or n*log(n) (depending on the implementation). Matrix multiplication is n<sup>3</sup>. This is a little weird because I think of the correlation coefficient as n<sup>2</sup> since that is the number of pairwise correlations you are computing and according to a cs stackexchange post, pearson correlation is O(n) [5].</p>

<h1>CWAS Complexity</h1>

<p>So I guess that&rsquo;s all the background I need. Now let&rsquo;s figure out the complexity of CWAS. Since the computation of the connectivity maps is shared amongst many algorithms, I will ignore that step and start from the computation of the distance matrices.</p>

<h2>Distance Matrices</h2>

<p>This step is done independently at each voxel. And, at a voxel, we have connectivity with m voxels across n participants. On this <code>mxn</code> matrix, we compute the pearson correlation between the m connectivity maps for all possible pairs of participants. Assuming that each correlation is computed in O(n) time [5], changing the number of voxels will lead to an O(n) change while changing the number of subjects will lead to an O(n<sup>2</sup>) change. Thus, this step should be O(V*n<sup>2</sup>).</p>

<h2>MDMR</h2>

<h3>Hat Matrix</h3>

<p>This step involves <code>H = X ( X^T X )^-1 X^T</code>. Note that <code>X</code> is n participants x k regressors. So from the formula, we can see that there are</p>

<ul>
<li>3 matrix algebra operations</li>
<li>1 matrix inversion</li>
<li>2 transpositions (but I won&rsquo;t count those)</li>
</ul>


<p>Each of these operations is O(k<em>n<sup>2</sup>) [4] so this step has O(k</em>n<sup>2</sup>) complexity. This I believe would be around the complexity of multiple linear regression for one voxel as well [6].</p>

<h3>Gower Matrix</h3>

<p>This step involves <code>G = (I - 11^T/n) * A * (I - 11^T/n)</code>. Note that <code>I</code> is the identity matrix (n x n), <code>1</code> is a vector of n 1&rsquo;s, and <code>A</code> is half the squared distance matrix. So from the formula, we can see</p>

<ul>
<li>2 subtractions (additions)</li>
<li>2 divisions (multiplications)</li>
<li>2 matrix multiplications</li>
</ul>


<p>Since the matrix operation will dominate the time, the complexity is O(V*n<sup>3</sup>) where V is the number of voxels.</p>

<h3>Pseudo-F Statistic</h3>

<p>This step involves <code>(HG/(k-1))/((I-H)G/(n-m))</code>. The division parts are not really relevant for the complexity and indeed are not needed when computing the permutations (McArdle and Anderson, 2001), so we actually have <code>(HG)/((I-H)G)</code>. Here H is a vector of hat matrix vectors so it&rsquo;s a P x n<sup>2</sup> matrix (P = # of permutations) and G is a vector of gower matrices so it&rsquo;s a n<sup>2</sup> x V matrix (V = # of voxels). This means that there are:</p>

<ul>
<li>1 subtraction (I-H)</li>
<li>2 matrix multiplications</li>
<li>1 division</li>
</ul>


<p>Since the matrix multiplication takes the dominant time, we can ignore the other two division operations. The computational complexity is then O(Pxn<sup>2xV</sup>) so as in the distance matrix step the complexity will scale by n<sup>2</sup>.</p>

<h1>References</h1>

<ol>
<li><a href="http://www.csd.uwo.ca/courses/CS1037a/notes/topic13_AnalysisOfAlgs.pdf">http://www.csd.uwo.ca/courses/CS1037a/notes/topic13_AnalysisOfAlgs.pdf</a></li>
<li><a href="http://en.wikipedia.org/wiki/Time_complexity">http://en.wikipedia.org/wiki/Time_complexity</a></li>
<li><a href="http://www-fourier.ujf-grenoble.fr/~demailly/manuscripts/kvpy-print.pdf">http://www-fourier.ujf-grenoble.fr/~demailly/manuscripts/kvpy-print.pdf</a></li>
<li><a href="http://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations">http://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations</a></li>
<li><a href="http://cs.stackexchange.com/questions/2604/whats-the-complexity-of-spearmans-rank-correlation-coefficient-computation">http://cs.stackexchange.com/questions/2604/whats-the-complexity-of-spearmans-rank-correlation-coefficient-computation</a></li>
<li><a href="http://math.stackexchange.com/questions/84495/computational-complexity-of-least-square-regression-operation">http://math.stackexchange.com/questions/84495/computational-complexity-of-least-square-regression-operation</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Another Quick Pack Journey]]></title>
    <link href="http://czarrar.github.io/blog/2013/10/30/another-look-at-quick-pack-journey/"/>
    <updated>2013-10-30T15:55:00-04:00</updated>
    <id>http://czarrar.github.io/blog/2013/10/30/another-look-at-quick-pack-journey</id>
    <content type="html"><![CDATA[<p>Today, I&rsquo;ve got through a few things. First, I finished compiling the <code>regressors.csv</code> file for</p>

<p>Some minor things, I helped Krishna with some ROI error he had in CPAC. It turned out that his issue was due to incorrectly binarizing the mask.</p>

<h1>QuickPack</h1>

<p>Trying my hand again on quick pack today. Last time I got a bunch of different errors that I really couldn&rsquo;t track. I am re-running the complete run to see what errors I get again and try to figure those out. I&rsquo;m also rerunning the alff to see what happens there.</p>

<h2>Complete Run</h2>

<p>This appears to be re-running smoothly (knock on wood). The last time I ran a complete (preprocessing + derivatives) run, it led to some unclear problems.</p>

<h2>ALFF QP</h2>

<p>I get the same link error as I did before. The error occurs on line 562 in <code>utils.py</code> within the <code>create_symbolic_links</code>. The line and error are</p>

<pre><code>ext = fname.split('.', 1)[1]
IndexError: list index out of range
</code></pre>

<p>Basically <code>fname</code> should be a filename but a directory is passed instead and so it fails. Specifically, it appears to be passing <code>/home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/ALFF_Output/pipeline_0/0051466_session_1/functional_freq_filtered/_scan_rest_1_rest/sinker_16</code>. I don&rsquo;t have much sense about what is going on with this file.</p>

<p>Other bits of information:</p>

<ul>
<li>The crash file is located <code>/home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/crash/crash-20131030-145001-milham-link_16.a0.np
z</code>.</li>
<li>The directory in the working directory is <code>/data/Projects/ABIDE_Initiative/CPAC/test_qp/ALFF_Working/resting_preproc_0051466_session_1/_scan_rest_1_rest/link_16</code></li>
</ul>


<h3>Steve Talk</h3>

<p>I discussed this issue with Steve and it seems I will need to get down and dirty with nipype to understand the origin of this problem.</p>

<h2>REHO QP</h2>

<p>Here I got two errors. One of the errors was the same as with ALFF except instead of link_16 it is link_5. The other error is new and specific to REHO with the crash file: <code>/home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/crash/crash-20131030-164123-milham-reho_map.a0.a0.npz</code>. It appears the error is an empty input filename being passed to the <code>compute_reho</code> in <code>reho/utils</code>.</p>

<p>A snapshot of the error is given below:</p>

<pre><code>/data/Projects/ABIDE_Initiative/CPAC/test_qp/Reho_Working/resting_preproc_0051466_session_1/reho_0/_scan_rest_1_rest/_scan_rest_1_rest/reho_map/&lt;string&gt; in compute_reho(in_file, mask_file, cluster_size)

/home/data/PublicProgram/epd-7.2-2-rh5-x86_64/lib/python2.7/site-packages/nibabel/loadsave.pyc in load(filename)
     37     except KeyError:
     38         raise ImageFileError('Cannot work out file type of "%s"' %
---&gt; 39                              filename)
     40     if ext in ('.nii', '.mnc', '.mgh', '.mgz'):
     41         klass = class_map[img_type]['class']

ImageFileError: Cannot work out file type of ""
Interface Function failed to run. 
</code></pre>

<p>To run the crash file, see the code below.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'><span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s">&#39;/home2/data/Projects/CPAC_Regression_Test/nipype-installs/fcp-indi-nipype/running-install/lib/python2.7/site-packages&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s">&quot;/home2/data/Projects/CPAC_Regression_Test/2013-05-30_cwas/C-PAC&quot;</span><span class="p">)</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">CPAC</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">CPAC.reho.utils</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">nipype.utils.filemanip</span> <span class="kn">import</span> <span class="n">loadflat</span>
</span><span class='line'>
</span><span class='line'><span class="n">crashinfo</span> <span class="o">=</span> <span class="n">loadflat</span><span class="p">(</span><span class="s">&quot;/home2/data/Projects/ABIDE_Initiative/CPAC/test_qp/crash/crash-20131030-164123-milham-reho_map.a0.a0.npz&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">crashinfo</span><span class="p">[</span><span class="s">&#39;node&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<h1>Preprocessing EmotionalBS</h1>

<p>I am going to preprocess the emotionalBS data again with CPAC+ANTS. Some relevant parameters are:</p>

<ul>
<li>Used ANTS for registration</li>
<li>Two nuisance correction strategies

<pre><code>  * compcor+motion+linear+quadratic
  * compcor+global+motion+linear+quadratic
</code></pre></li>
<li>Both frequency filtering (0.01-0.1 Hz) and no filtering</li>
<li>Smoothing of 4.5mm (only for derivatives)</li>
<li>Generated some SCA and drSCA based derivates using ROIs/maps from the ABIDE preprocessing. Otherwise no other derivatives were created.</li>
</ul>


<h2>Install FSL 5 for Gelert</h2>

<p>I was a little confused on how to install fsl 5 to a custom path (<code>/home2/data/PublicProgram</code>). It seemed to go through neurodebian and apt-get, I needed certain admin privileges that even Mike&rsquo;s account didn&rsquo;t have. And even if I had those, it wasn&rsquo;t clear how I would install to a custom directory. Then I realized I could just copy the current fsl5 in <code>/usr/share/fsl/5.o</code> into that directory. The reason for this (<code>/home2/data/PublicProgram</code>) directory is so</p>

<h1>New Journal</h1>

<p>I also worked on setting up this blog/journal with github user account. The goal is to chronicle my work efforts with particular thought on any issues I encounter. A major side benefit will be easier communication with others in the lab (e.g., was able to easily show the error for ALFF quick pack to Steve). Previously, I had been using different journal pages for each of my projects. I ended up being a big confused where to post stuff and often lost track of the markdown pages that I had created before they were published. With one journal site, this should all be easier.</p>

<p>I&rsquo;m also testing out this slightly different jekyll wrapper (octopress). I unfortunately spent a lot longer (2 hours) setting it up cuz of a git error then I had wanted. So I hope some of its benefits over jekyll bootstrap such as easier syncing, simpler interface, and simpler integration of more advanced plugins, will be useful in the long run. That way I can justify my time spent installing it!</p>
]]></content>
  </entry>
  
</feed>
